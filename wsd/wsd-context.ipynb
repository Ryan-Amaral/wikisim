{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "\n",
    "import os\n",
    "import time;\n",
    "import json \n",
    "import requests\n",
    "import numpy as np\n",
    "        \n",
    "\n",
    "# %aimport wikipedia\n",
    "# %aimport calcsim\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from wikisim.config import *\n",
    "from wikisim.calcsim import *\n",
    "\n",
    "\n",
    "def generate_candidates(S, M, max_t=10, enforce=True):\n",
    "    candslist=[]\n",
    "    for m in M:\n",
    "        wid = title2id(m[1])\n",
    "        if wid is None:\n",
    "            raise Exception(m[1].encode('utf-8') + ' not found')\n",
    "        \n",
    "        clist = anchor2concept(S[m[0]])\n",
    "        clist = sorted(clist, key=lambda x: -x[1])\n",
    "\n",
    "        smooth=0    \n",
    "        trg = [(i,(c,f)) for i,(c,f) in enumerate(clist) if c==wid]\n",
    "        if not trg:\n",
    "            trg=[(len(clist), (wid,0))]\n",
    "            smooth=1\n",
    "\n",
    "            \n",
    "        clist = clist[:max_t]\n",
    "        if smooth==1 or trg[0][0]>=max_t: \n",
    "            if clist:\n",
    "                clist.pop()\n",
    "            clist.append(trg[0][1])\n",
    "        s = sum(c[1]+smooth for c in clist )        \n",
    "        clist = [(c,float(f+smooth)/s) for c,f in clist ]\n",
    "            \n",
    "        candslist.append(clist)\n",
    "    return  candslist \n",
    "\n",
    "def disambiguate(C, method, direction, op_method):\n",
    "        \n",
    "    if op_method == 'ilp':\n",
    "        return disambiguate_ilp(C, method, direction)\n",
    "    if op_method == 'ilp2':\n",
    "        return disambiguate_ilp_2(C, method, direction)\n",
    "    if  op_method == 'context1'  :\n",
    "        return contextdisamb_1(C, direction)\n",
    "    if  op_method == 'context2'  :\n",
    "        return contextdisamb_2(C, direction)\n",
    "    if  op_method == 'context3'  :\n",
    "        return contextdisamb_3(C, direction)\n",
    "    \n",
    "    if  op_method == 'context4_1'  :\n",
    "        return contextdisamb_4(C, direction, 1)\n",
    "    if  op_method == 'context4_2'  :\n",
    "        return contextdisamb_4(C, direction, 2)\n",
    "    if  op_method == 'context4_3'  :\n",
    "        return contextdisamb_4(C, direction, 3)\n",
    "    if  op_method == 'context4_4'  :\n",
    "        return contextdisamb_4(C, direction, 4)\n",
    "    \n",
    "    if  op_method == 'tagme'  :\n",
    "        return tagme(C, method, direction)\n",
    "    if  op_method == 'tagme2'  :\n",
    "        return tagme(C, method, direction, True)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def disambiguate_driver(C, ws, method, direction, op_method):\n",
    "    ids = []\n",
    "    titles = []\n",
    "    \n",
    "    windows = [[start, min(start+ws, len(C))] for start in range(0,len(C),ws) ]\n",
    "    last = len(windows)\n",
    "    if last > 1 and windows[last-1][1]-windows[last-1][0]<3:\n",
    "        windows[last-2][1] = len(C)\n",
    "        windows.pop()\n",
    "        \n",
    "    for w in windows:\n",
    "        chunk_c = C[w[0]:w[1]]\n",
    "        chunk_ids, chunk_titles = disambiguate(chunk_c, method, direction, op_method)\n",
    "        ids += chunk_ids\n",
    "        titles += chunk_titles\n",
    "    return ids, titles     \n",
    "\n",
    "def get_tp(gold_titles, ids):\n",
    "    tp=0\n",
    "    for m,id2 in zip(gold_titles, ids):\n",
    "        if title2id(m[1]) == id2:\n",
    "            tp += 1\n",
    "    return [tp, len(ids)]\n",
    "\n",
    "def get_prec(tp_list):\n",
    "    if not tp_list:\n",
    "        return 0, 0\n",
    "    overall_tp = 0\n",
    "    overall_count=0\n",
    "    macro_prec = 0;\n",
    "    for tp, count in tp_list:\n",
    "        overall_tp += tp\n",
    "        overall_count += count\n",
    "        macro_prec += float(tp)/count\n",
    "        \n",
    "    macro_prec = macro_prec/len(tp_list)\n",
    "    micro_prec = float(overall_tp)/overall_count\n",
    "    \n",
    "    return micro_prec, macro_prec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload\n",
    "\n",
    "#%aimport wsd\n",
    "\n",
    "#from wsd import *\n",
    "import time\n",
    "S=[\"Major League Baseball\", \"New York City\", \"Major League Baseball\", \"American League\",\n",
    "            \"Boston Red Sox\", \"Seattle Mariners\", \"Cleveland Indians\", \"Milwaukee Brewers\", \"Baltimore Orioles\",\n",
    "            \"Oakland Athletics\", \"New York Yankees\", \"Chicago White Sox\", \"Toronto Blue Jays\", \"Texas Rangers\", \n",
    "            \"Minnesota Twins\", \"Detroit Tigers\", \"Kansas City Royals\"]\n",
    "M=[[0, \"Major_League_Baseball\"], [1, \"New_York_City\"], [2, \"Major_League_Baseball\"], [3, \"American_League\"],\n",
    "   [4, \"Boston_Red_Sox\"], [5, \"Seattle_Mariners\"], [6, \"Cleveland_Indians\"], [7, \"Milwaukee_Brewers\"],\n",
    "   [8, \"Baltimore_Orioles\"], [9, \"Oakland_Athletics\"], [10, \"New_York_Yankees\"], [11, \"Chicago_White_Sox\"],\n",
    "   [12, \"Toronto_Blue_Jays\"], [13, \"Texas_Rangers_(baseball)\"], [14, \"Minnesota_Twins\"], [15, \"Detroit_Tigers\"],\n",
    "   [16, \"Kansas_City_Royals\"]]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "C = generate_candidates(S, M, 10)\n",
    "#print C\n",
    "#try:\n",
    "ids, titles = disambiguate_driver(C, 5, 'rvspagerank', 2, 'ilp2')\n",
    "#except:\n",
    "    #print \"Error\"\n",
    "\n",
    "#elapsed = str(timeformat(int(time.time()-start)));\n",
    "#print ids\n",
    "#\n",
    "print titles\n",
    "\n",
    "tp = get_tp(M, ids) \n",
    "print tp\n",
    "#prinbt elapsed\n",
    "# prec = get_prec(tp)\n",
    "# print prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cripples wsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "%aimport wsd\n",
    "\n",
    "import sys\n",
    "\n",
    "#from wsd import *\n",
    "\n",
    "\n",
    "\n",
    "dsnames = [os.path.join(home,'backup/datasets/ner/kore.json'),\n",
    "          os.path.join(home,'backup/datasets/ner/aida.json'), \n",
    "          os.path.join(home,'backup/datasets/ner/wiki-mentions.5000.json')]\n",
    "\n",
    "#dsnames = [os.path.join(home,'backup/datasets/ner/wiki-mentions.json'), \n",
    "#           os.path.join(home,'backup/datasets/ner/kore.json')]\n",
    "\n",
    "dsnames = [os.path.join(home,'backup/datasets/ner/kore.json')]\n",
    "\n",
    "methods = (('wlm', DIR_IN,'ilp'), ('rvspagerank', DIR_OUT, 'ilp'))\n",
    "\n",
    "methods = (\n",
    "           ('rvspagerank', DIR_OUT, 'context3'),\n",
    "           ('rvspagerank', DIR_OUT, 'context3'),\n",
    "           ('rvspagerank', DIR_OUT, 'context1'))\n",
    "\n",
    "# methods = (('wlm', DIR_IN,'ilp'), ('rvspagerank', DIR_OUT, 'ilp'))\n",
    "#methods = (('wlm', DIR_IN, 'tagme'),)\n",
    "#methods = (('rvspagerank', DIR_BOTH, 'ilp2'), )\n",
    "methods = (('rvspagerank', DIR_BOTH, 'context4_4'), )\n",
    "\n",
    "max_t=5\n",
    "max_count=5\n",
    "ws=3\n",
    "verbose=True\n",
    "restart = True\n",
    "\n",
    "outdir = os.path.join(baseresdir, 'wsd')\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "resname =  os.path.join(outdir, 'reslog.txt')\n",
    "#clearlog(resname)\n",
    "\n",
    "detailedresname=  os.path.join(outdir, 'detailedreslog.txt')\n",
    "#clearlog(detailedresname)\n",
    "\n",
    "\n",
    "for method, direction, op_method in methods:\n",
    "    for dsname in dsnames:\n",
    "        start = time.time()\n",
    "        \n",
    "        print \"dsname: %s, method: %s, op_method: %s, direction: %s, max_t: %s, ws: %s ...\"  % (dsname,\n",
    "                method, op_method, direction, max_t, ws)\n",
    "        sys.stdout.flush()\n",
    "        tmpfilename = os.path.join(outdir, \n",
    "                                   '-'.join([method, str(direction), op_method, str(max_t), str(ws), os.path.basename(dsname)]))\n",
    "        \n",
    "        overall=[]\n",
    "        start_count=-1\n",
    "        if os.path.isfile(tmpfilename):\n",
    "            if restart:\n",
    "                os.remove(tmpfilename)\n",
    "            else:\n",
    "                with open(tmpfilename,'r') as tmpf:\n",
    "                    for line in tmpf:\n",
    "                        js = json.loads(line.strip())\n",
    "                        start_count = js['no']\n",
    "                        if js['tp'] is not None:\n",
    "                            overall.append(js['tp'])\n",
    "        \n",
    "        if start_count !=-1:\n",
    "            print \"Continuing from\\t\", start_count\n",
    "        count=0\n",
    "        with open(dsname,'r') as ds, open(tmpfilename,'a') as tmpf:\n",
    "            for line in ds:\n",
    "                js = json.loads(line.decode('utf-8').strip());\n",
    "                S = js[\"text\"]\n",
    "                M = js[\"mentions\"]\n",
    "                count +=1\n",
    "                if count <= start_count:\n",
    "                    continue\n",
    "                if verbose:\n",
    "                    print \"%s:\\tS=%s\\n\\tM=%s\" % (count, json.dumps(S, ensure_ascii=False),json.dumps(M, ensure_ascii=False))\n",
    "                    sys.stdout.flush()\n",
    "                    \n",
    "                C = generate_candidates(S, M, max_t=max_t, enforce=True)\n",
    "                try:\n",
    "                    ids, titles = disambiguate_driver(C, ws, method, direction, op_method)\n",
    "                except:\n",
    "                    print \"Error\"\n",
    "                    tmpf.write(json.dumps({\"no\":count, \"tp\":None})+\"\\n\")\n",
    "                    continue\n",
    "                    \n",
    "                tp = get_tp(M, ids) \n",
    "                overall.append(tp)\n",
    "                tmpf.write(json.dumps({\"no\":count, \"tp\":tp})+\"\\n\")\n",
    "                if (max_count !=-1) and (count >= max_count):\n",
    "                    break\n",
    "                    \n",
    "\n",
    "        elapsed = str(timeformat(int(time.time()-start)));\n",
    "        print \"done\"\n",
    "        detailedres ={\"dsname\":dsname, \"method\": method, \"op_method\": op_method, \"driection\": direction,\n",
    "                      \"max_t\": max_t, \"tp\":overall, \"elapsed\": elapsed, \"ws\": ws}\n",
    "        \n",
    "        \n",
    "        #logres(detailedresname, '%s',  json.dumps(detailedres))\n",
    "        #print('%s',  json.dumps(detailedres))\n",
    "        \n",
    "        micro_prec, macro_prec = get_prec(overall)        \n",
    "        #logres(resname, '%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s', method, op_method, graphtype(direction), max_t , ws, \n",
    "               #dsname, micro_prec, macro_prec, elapsed)\n",
    "        print '%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s'% (method, op_method, graphtype(direction), max_t , ws, \n",
    "               dsname, micro_prec, macro_prec, elapsed)\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "wlm\ttagme\tin\t20\t5\t/home/sajadi/backup/datasets/ner/wiki-mentions.json\t0.607142857143\t0.58427045177\t0:05:47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

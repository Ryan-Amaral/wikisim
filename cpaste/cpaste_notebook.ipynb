{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General input output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_sentece(str):\n",
    "    # S=\"I met David Beckham and Victoria in Madrid\"\n",
    "    # Solr = \"I met *David Beckham* and *Victoria* in *Madrid*\"\n",
    "    # S = [I,met, David Beckham, .... ] using string.punctuation + white_spaces\n",
    "    # M=[2,4,5]\n",
    "    returns S,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_candidates(S, max_t=10, enforce=True):\n",
    "    \"\"\" Given a sentence list (S) and  a mentions list (M), returns a list of candiates\n",
    "        Inputs:\n",
    "            S: segmented sentence [w1, ..., wn]\n",
    "            M: mensions [m1, ... , mj]\n",
    "            max_t: maximum candiate per mention\n",
    "            enforce: Makes sure the \"correct\" entity is among the candidates\n",
    "        Outputs:\n",
    "         Candidate list [[(c11, p11),...(c1k, p1k)],...[(cn1, pn1),...(c1m, p1m)]]\n",
    "             where cij is the jth candidate for ith mention and pij is the relative frequency of cij\n",
    "    \n",
    "    \"\"\"\n",
    "    candslist=[]\n",
    "    for m in M:\n",
    "#         wid = title2id(m[1])\n",
    "#         if wid is None:\n",
    "#             raise Exception(m[1].encode('utf-8') + ' not found')\n",
    "        \n",
    "        clist = anchor2concept(S[m[0]])\n",
    "        clist = sorted(clist, key=lambda x: -x[1])\n",
    "\n",
    "        smooth=0    \n",
    "        trg = [(i,(c,f)) for i,(c,f) in enumerate(clist) if c==wid]\n",
    "        if enforce and (not trg):\n",
    "            trg=[(len(clist), (wid,0))]\n",
    "            smooth=1\n",
    "\n",
    "            \n",
    "        clist = clist[:max_t]\n",
    "        if enforce and (smooth==1 or trg[0][0]>=max_t): \n",
    "            if clist:\n",
    "                clist.pop()\n",
    "            clist.append(trg[0][1])\n",
    "        s = sum(c[1]+smooth for c in clist )        \n",
    "        clist = [(c,float(f+smooth)/s) for c,f in clist ]\n",
    "            \n",
    "        candslist.append(clist)\n",
    "    return  candslist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from wsd.wsd import *\n",
    "\n",
    "S=[\"Carlos\", \"met\", \"David\", \"and\" , \"Victoria\", \"in\", \"Madrid\"]\n",
    "M=[[2, \"David_Beckham\"], [4, \"Victoria_Beckham\"], [6, \"Madrid\"]]\n",
    "\n",
    "C=generate_candidates(S, M, max_t=3, enforce=False)\n",
    "def get_popularity(C):\n",
    "    scores=[]\n",
    "    for c in C:\n",
    "        s=[x[1] for x in c]\n",
    "        scores.append(s)\n",
    "    return scores\n",
    "        \n",
    "P=get_popularity(C)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajadi/anaconda2/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from wikisim.calcsim import *\n",
    "word2vec = gensim_loadmodel('/home/sajadi/backup/wikipedia/WikipediaClean5Negative300Skip10.Ehsan/WikipediaClean5Negative300Skip10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=getentity2vector(encode_entity('David_Beckham','word2vec_id'))\n",
    "y=getentity2vector(encode_entity('David', 'word2vec_id'))\n",
    "context=getword2vector('soccer') + getword2vector('Victoria')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.369183122053\n",
      "0.0909524586892\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import scipy.sparse as sprs\n",
    "import scipy.spatial\n",
    "import scipy.sparse.linalg \n",
    "#panda vector\n",
    "print 1-sp.spatial.distance.cosine(context, x);\n",
    "print 1-sp.spatial.distance.cosine(context, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.286691\n",
       "1      0.309643\n",
       "2     -0.440182\n",
       "3     -0.215264\n",
       "4      0.363785\n",
       "5     -0.298642\n",
       "6      0.574758\n",
       "7     -0.094513\n",
       "8      0.318274\n",
       "9     -0.188464\n",
       "10     0.158765\n",
       "11    -0.257204\n",
       "12     0.237741\n",
       "13    -0.257524\n",
       "14     0.288563\n",
       "15     0.545386\n",
       "16    -0.393122\n",
       "17    -0.317044\n",
       "18    -0.169808\n",
       "19     0.098242\n",
       "20    -0.258380\n",
       "21    -0.262747\n",
       "22    -0.194904\n",
       "23    -0.444793\n",
       "24     0.277448\n",
       "25    -0.025654\n",
       "26     0.287121\n",
       "27     0.086031\n",
       "28    -0.122469\n",
       "29    -0.239167\n",
       "         ...   \n",
       "270   -0.426469\n",
       "271    0.274891\n",
       "272   -0.258263\n",
       "273   -0.112344\n",
       "274   -0.116418\n",
       "275    0.355874\n",
       "276    0.386146\n",
       "277    0.044444\n",
       "278   -0.362351\n",
       "279   -0.217038\n",
       "280    0.320433\n",
       "281   -0.161443\n",
       "282   -0.083336\n",
       "283    0.226705\n",
       "284    0.167725\n",
       "285    0.398921\n",
       "286   -0.117666\n",
       "287    0.395689\n",
       "288   -0.112931\n",
       "289   -0.145321\n",
       "290   -0.136716\n",
       "291   -0.071161\n",
       "292   -0.309932\n",
       "293    0.302323\n",
       "294    0.217616\n",
       "295    0.093228\n",
       "296   -0.085171\n",
       "297    0.438386\n",
       "298   -0.120025\n",
       "299    0.221915\n",
       "dtype: float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getword2vector('soccer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named embeddings",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-94e3fd7f3fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named embeddings"
     ]
    }
   ],
   "source": [
    "from gensim import *\n",
    "from embeddings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Notebook\n",
    "This notebook provided some methods to do evaluate Wikisim on different datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%system\n",
    "\n",
    "mysql -u root -pemilios -e 'set global key_buffer_size=4*1024*1024*1024;'\n",
    "mysql -u root -pemilios -e 'set global bulk_insert_buffer_size=1024*1024*1024;'\n",
    "mysql -u root -pemilios -e 'set global query_cache_size = 4*1024*1024*1024;'\n",
    "mysql -u root -pemilios -e 'set global query_cache_limit = 4*1024*1024*1024;'\n",
    "mysql -u root -pemilios -e 'set global tmp_table_size = 4*1024*1024*1024;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "home = os.path.expanduser(\"~\");\n",
    "dsdir = os.path.join(home ,\"backup/projects/wikisim/datasets/\");\n",
    "workingdir = os.path.join(home , 'backup/tmp/');\n",
    "baseresdir = path = os.path.join(workingdir, 'results')\n",
    "\n",
    "logging.basicConfig(filename=os.path.join(workingdir,'myapp.log'), level=logging.INFO);    \n",
    "\n",
    "    \n",
    "def resdir(direction, hitsver):   \n",
    "    path = os.path.join(baseresdir , graphtype(direction), hitsver);\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return path\n",
    "\n",
    "    \n",
    "def tmpdir(direction, hitsver):\n",
    "    return os.path.join(resdir(direction, hitsver),'tmp/');\n",
    "\n",
    "def graphdir(direction):    \n",
    "    return os.path.join(getworkingdir , 'graphs' , wikisim.graphtypestr(direction));\n",
    "\n",
    "def initdirs(direction, hitsver):\n",
    "    path = resdir(direction, hitsver)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    path = tmpdir(direction, hitsver)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "def printflush(*str):\n",
    "    print str\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "def graphtype(direction):\n",
    "    if direction == DIR_IN:\n",
    "        return 'in'\n",
    "    if direction == DIR_OUT:\n",
    "        return 'out'\n",
    "    if direction == DIR_BOTH:\n",
    "        return 'both' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# In-Out degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from collections import defaultdict\n",
    "with open(home+\"/backup/projects/datasets/embed/allids.csv\") as f:\n",
    "    allids=set(line.strip() for line in f);\n",
    "#outcount = defaultdict();    \n",
    "for id in allids:\n",
    "    if not id.isdigit(): continue;\n",
    "    outcount[id]=len(getlinkedpages(id,Wikipedia.DIR_IN));\n",
    "#o=w.getlinkedpages_query('None',Wikipedia.DIR_OUT);\n",
    "#print o;\n",
    "#w.cursor.execute(o)\n",
    "#s=w.getlinkedpages_query(29953972,Wikipedia.DIR_OUT);\n",
    "outcount_sorted=sorted(outcount.items(), key=operator.itemgetter(1))\n",
    "print outcount_sorted\n",
    "\n",
    "w.close();    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluating rvspage rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Processing', 'MiniMayoSRS-edited.csv')\n",
      "(0.68416972848512614, 4.2679377614525189e-05)\n",
      "0:00:05\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import os\n",
    "import time;\n",
    "#D = sparse(k,k,1./c(k),n,n);\n",
    "\n",
    "# %autoreload 1\n",
    "\n",
    "# %aimport wikipedia\n",
    "# %aimport visualize\n",
    "# from visualize import *\n",
    "# from wikipedia import *\n",
    "\n",
    "direction=DIR_OUT;\n",
    "initdirs(direction, 'rvspagerank')\n",
    "resfilename =  os.path.join(baseresdir, 'reslog.txt')\n",
    "\n",
    "dsfiles=('MC_28-edited.csv', 'MiniMayoSRS-edited.csv',)\n",
    "dsfiles=('MiniMayoSRS-edited.csv',)\n",
    "start = time.time()\n",
    "for dsname in dsfiles:\n",
    "    printflush (\"Processing\",dsname)\n",
    "    dsbase, dsext = os.path.splitext(dsname);\n",
    "    infilename = os.path.join(dsdir, dsname)\n",
    "    outfilename = os.path.join(resdir(direction, 'rvspagerank'), dsbase+ '.out'+ dsext)\n",
    "    _ , corr = getsim_file(infilename, outfilename, direction);\n",
    "    logres(resfilename, 'rvspagerank\\t%s\\t%s', graphtype(direction), corr)\n",
    "    print corr\n",
    "    \n",
    "print str(timeformat(int(time.time()-start)));\n",
    "#close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Processing', 'MiniMayoSRS-edited.csv')\n",
      "Renal_failuredone\n",
      "Abortiondone\n",
      "Heartdone\n",
      "Strokedone\n",
      "Delusiondone\n",
      "Calcificationdone\n",
      "Metastasisdone\n",
      "Congestive_heart_failuredone\n",
      "Pulmonary_fibrosisdone\n",
      "Diarrheadone\n",
      "Mitral_stenosisdone\n",
      "Brain_tumordone\n",
      "Antibioticdone\n",
      "Pulmonary_embolusdone\n",
      "Carpal_tunnel_syndromedone\n",
      "Rheumatoid_arthritisdone\n",
      "Acnedone\n",
      "Diabetes_mellitusdone\n",
      "Cortisonedone\n",
      "Cholangiocarcinomadone\n",
      "Lymphoid_hyperplasiadone\n",
      "Appendicitisdone\n",
      "Depressive_disorderdone\n",
      "Hyperlipidemiadone\n",
      "Multiple_sclerosisdone\n",
      "Peptic_ulcer_diseasedone\n",
      "Rectal_polypdone\n",
      "Varicose_veindone\n",
      "Xerostomiadone\n",
      "0:00:03\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import os\n",
    "import time;\n",
    "import json\n",
    "\n",
    "\n",
    "%aimport wikipedia\n",
    "from calcsim import *\n",
    "from wikipedia import *\n",
    "\n",
    "#D = sparse(k,k,1./c(k),n,n);\n",
    "\n",
    "# %autoreload 1\n",
    "\n",
    "# %aimport wikipedia\n",
    "# %aimport visualize\n",
    "# from visualize import *\n",
    "# from wikipedia import *\n",
    "\n",
    "direction=DIR_OUT;\n",
    "initdirs(direction, 'rvspagerank')\n",
    "\n",
    "dsfiles=('MC_28-edited.csv', 'MiniMayoSRS-edited.csv',)\n",
    "dsfiles=('MiniMayoSRS-edited.csv',)\n",
    "start = time.time()\n",
    "for dsname in dsfiles:\n",
    "    printflush (\"Processing\",dsname)\n",
    "    dsbase, dsext = os.path.splitext(dsname);\n",
    "    infilename = os.path.join(dsdir, dsname)\n",
    "    outfilename = os.path.join(resdir(direction, 'rvspagerank'), dsbase+ '.emb'+ dsext)\n",
    "    getembed_file(infilename, outfilename,direction, cutoff=3);\n",
    "    \n",
    "print str(timeformat(int(time.time()-start)));\n",
    "#close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.67\n",
      "[23.677454, 23.3334554564597, 23.0003434343487]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.2f')\n",
    "\n",
    "print json.dumps(23.67)\n",
    "print json.dumps([23.677454, 23.3334554564597, 23.0003434343487])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

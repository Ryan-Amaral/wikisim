{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'My', u'O'),\n",
       " (u'name', u'O'),\n",
       " (u'is', u'O'),\n",
       " (u'Ryan', u'PERSON'),\n",
       " (u'Amaral', u'PERSON'),\n",
       " (u'I', u'O'),\n",
       " (u'am', u'O'),\n",
       " (u'a', u'O'),\n",
       " (u'student', u'O'),\n",
       " (u'at', u'O'),\n",
       " (u'Dalhousie', u'LOCATION'),\n",
       " (u'in', u'O'),\n",
       " (u'Halifax.', u'LOCATION')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "\n",
    "ner = StanfordNERTagger('/users/cs/amaral/CoreNLP/stanford-ner-2017-06-09/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "               '/users/cs/amaral/CoreNLP/stanford-ner-2017-06-09/stanford-ner.jar')\n",
    "ner.tag('My name is Ryan Amaral I am a student at Dalhousie in Halifax.'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ryan Amaral\n",
      "Dalhousie University\n",
      "Halifax\n",
      "Nova Scotia\n"
     ]
    }
   ],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "text = 'Ryan Amaral is a student at Dalhousie University in Halifax, Nova Scotia.'\n",
    "output = nlp.annotate(text, properties={\n",
    "    'annotators': 'entitymentions',\n",
    "    'outputFormat': 'json'\n",
    "})\n",
    "for mention in output['sentences'][0]['entitymentions']:\n",
    "    print mention['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 11, 37, 0, 0, 1, 1, 0]\n",
      "[11, 37, 14, 0, 0, 0, 0, 0]\n",
      "[37, 14, 20, 1.1691849611635728e-05, 0, 0, 0, 0]\n",
      "[14, 20, 22, 0.0571872685237144, 1, 1, 1, 1]\n",
      "[20, 22, 13, 0.00022617078721569626, 0, 0, 0, 0]\n",
      "[22, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 37, 0.3469192549884422, 1, 1, 1, 1]\n",
      "[20, 37, 14, 0, 0, 0, 0, 0]\n",
      "[37, 14, 31, 0.0008894379770911345, 0, 0, 0, 0]\n",
      "[14, 31, 10, 0, 0, 0, 0, 0]\n",
      "[31, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 11, 0.0, 0, 0, 0, 0]\n",
      "[19, 11, 37, 0, 0, 1, 1, 0]\n",
      "[11, 37, 46, 0, 0, 0, 0, 0]\n",
      "[37, 46, 14, 5.343504516062842e-06, 0, 0, 0, 0]\n",
      "[46, 14, 22, 1.1691849611635728e-05, 0, 0, 0, 0]\n",
      "[14, 22, 39, 0.00022617078721569626, 0, 0, 0, 0]\n",
      "[22, 39, 37, 0, 0, 0, 0, 0]\n",
      "[39, 37, 46, 1.4363688595231255e-05, 0, 0, 0, 0]\n",
      "[37, 46, 33, 0, 0, 0, 0, 0]\n",
      "[46, 33, 14, 4.4276586983568955e-06, 0, 0, 0, 0]\n",
      "[33, 14, 14, 0.0006905800069058, 0, 0, 0, 0]\n",
      "[14, 14, 35, 0.0, 0, 0, 0, 0]\n",
      "[14, 35, 20, 4.948314851377364e-06, 0, 0, 0, 0]\n",
      "[35, 20, 4, 0.0414563806777217, 0, 1, 1, 1]\n",
      "[20, 4, 8, 0, 0, 0, 1, 0]\n",
      "[4, 8, 38, 0, 0, 0, 0, 0]\n",
      "[8, 38, 10, 0.00022617078721569626, 0, 0, 0, 0]\n",
      "[38, 10, 37, 0, 0, 0, 0, 0]\n",
      "[10, 37, 46, 2.381164039978157e-06, 0, 0, 0, 0]\n",
      "[37, 46, 36, 0, 0, 0, 0, 0]\n",
      "[46, 36, 14, 4.218579806670925e-06, 0, 0, 0, 0]\n",
      "[36, 14, 45, 0.0, 0, 0, 0, 0]\n",
      "Line: 1\n",
      "Error #1 on line #1\n",
      "[45, 10, 14, 0, 0, 1, 1, 0]\n",
      "[10, 14, 19, 0.2039454548565367, 1, 1, 1, 0]\n",
      "[14, 19, 13, 0.011770557029177718, 0, 0, 0, 0]\n",
      "[19, 13, 20, 5.5698094051005925e-06, 0, 0, 0, 0]\n",
      "[13, 20, 8, 0.13884347067800304, 1, 1, 1, 0]\n",
      "[20, 8, 20, 0, 0, 0, 0, 0]\n",
      "[8, 20, 22, 0.28146942778805645, 1, 1, 1, 0]\n",
      "[20, 22, 8, 0.0015259513458890871, 0, 0, 0, 0]\n",
      "[22, 8, 14, 0, 0, 0, 0, 0]\n",
      "[8, 14, 19, 0.2039454548565367, 1, 1, 1, 0]\n",
      "[14, 19, 13, 0.011770557029177718, 0, 0, 0, 0]\n",
      "[19, 13, 14, 5.5698094051005925e-06, 0, 0, 0, 0]\n",
      "[13, 14, 22, 0.13884347067800304, 1, 1, 1, 0]\n",
      "[14, 22, 37, 0.0015259513458890871, 0, 0, 0, 0]\n",
      "[22, 37, 14, 0.0, 0, 0, 0, 0]\n",
      "[37, 14, 14, 0, 0, 0, 0, 0]\n",
      "[14, 14, 14, 0.0, 0, 0, 0, 0]\n",
      "[14, 14, 20, 0.0, 0, 0, 0, 0]\n",
      "[14, 20, 20, 0, 0, 1, 0, 0]\n",
      "[20, 20, 34, 0.0, 0, 0, 0, 0]\n",
      "[20, 34, 10, 0, 0, 0, 0, 0]\n",
      "[34, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 19, 0.0, 0, 0, 0, 0]\n",
      "[19, 19, 14, 0.0, 0, 0, 0, 0]\n",
      "[19, 14, 19, 0.0, 0, 0, 0, 0]\n",
      "[14, 19, 8, 0.006858924395946999, 0, 0, 0, 0]\n",
      "[19, 8, 19, 0, 0, 0, 0, 0]\n",
      "[8, 19, 13, 0.0, 0, 0, 0, 0]\n",
      "[19, 13, 9, 0, 0, 0, 0, 0]\n",
      "[13, 9, 20, 0.0, 1, 0, 0, 0]\n",
      "[9, 20, 46, 0.0, 0, 1, 0, 0]\n",
      "[20, 46, 13, 2.895214933518627e-05, 0, 0, 0, 0]\n",
      "[46, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 8, 0.5230607966457023, 1, 1, 1, 1]\n",
      "[20, 8, 20, 0, 0, 0, 0, 0]\n",
      "[8, 20, 19, 0.30474732006125577, 1, 1, 1, 1]\n",
      "[20, 19, 13, 0.0, 0, 0, 0, 0]\n",
      "[19, 13, 20, 5.5698094051005925e-06, 0, 0, 0, 0]\n",
      "[13, 20, 8, 0.13884347067800304, 1, 1, 1, 1]\n",
      "[20, 8, 20, 0, 0, 0, 0, 0]\n",
      "[8, 20, 4, 0.06639839034205232, 0, 1, 1, 1]\n",
      "[20, 4, 46, 0, 0, 0, 1, 0]\n",
      "[4, 46, 13, 0.0, 0, 0, 0, 0]\n",
      "[46, 13, 9, 5.5698094051005925e-06, 0, 0, 0, 0]\n",
      "[13, 9, 31, 0.018478118591561586, 1, 0, 1, 0]\n",
      "[9, 31, 10, 0, 0, 0, 0, 0]\n",
      "[31, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 9, 7.657299718269162e-05, 0, 0, 0, 0]\n",
      "[14, 9, 22, 0.0, 0, 0, 0, 0]\n",
      "[9, 22, 37, 2.4060439824839997e-05, 0, 1, 0, 1]\n",
      "[22, 37, 29, 0.00012193577736402988, 0, 0, 0, 0]\n",
      "[37, 29, 10, 9.030189859741801e-05, 0, 0, 0, 0]\n",
      "[29, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 13, 0.0029868368343746268, 0, 0, 0, 0]\n",
      "[19, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 6, 0.15359477124183007, 1, 1, 1, 1]\n",
      "[20, 6, 45, 0, 0, 0, 0, 0]\n",
      "Line: 3\n",
      "[45, 20, 21, 0.1583991928703548, 0, 1, 1, 0]\n",
      "[20, 21, 46, 0.00047309793127177325, 0, 1, 1, 0]\n",
      "[21, 46, 20, 0.0, 0, 0, 0, 0]\n",
      "[46, 20, 20, 0.1583991928703548, 0, 1, 1, 0]\n",
      "[20, 20, 34, 0.0, 0, 1, 0, 0]\n",
      "[20, 34, 10, 0, 0, 0, 0, 0]\n",
      "[34, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 14, 0.03638720500209692, 1, 1, 1, 1]\n",
      "[20, 14, 19, 1.4123416058888995e-06, 0, 0, 0, 0]\n",
      "[14, 19, 8, 0.10253322437744614, 0, 0, 0, 0]\n",
      "[19, 8, 34, 0, 0, 0, 0, 0]\n",
      "[8, 34, 46, 0, 0, 0, 0, 0]\n",
      "[34, 46, 10, 5.343504516062842e-06, 0, 0, 0, 0]\n",
      "[46, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 19, 4.914677684905972e-05, 0, 0, 0, 0]\n",
      "[19, 19, 13, 0.02143811694947612, 0, 0, 0, 0]\n",
      "[19, 13, 22, 0, 0, 0, 0, 0]\n",
      "[13, 22, 36, 1.206896551724138, 1, 1, 1, 1]\n",
      "[22, 36, 13, 4.5194931388444784e-05, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 4, 0.18888888888888888, 1, 1, 1, 1]\n",
      "[20, 4, 20, 0, 0, 0, 1, 0]\n",
      "[4, 20, 4, 0.35164890534855014, 1, 1, 1, 1]\n",
      "[20, 4, 35, 0, 0, 0, 1, 0]\n",
      "[4, 35, 13, 4.914677684905972e-05, 0, 0, 0, 0]\n",
      "[35, 13, 20, 5.5698094051005925e-06, 0, 0, 0, 0]\n",
      "[13, 20, 20, 0.013677811550151976, 0, 1, 0, 0]\n",
      "[20, 20, 6, 1.1904761904761905, 1, 1, 1, 1]\n",
      "[20, 6, 13, 0, 0, 0, 0, 0]\n",
      "[6, 13, 20, 0, 0, 1, 1, 0]\n",
      "[13, 20, 9, 0.00037467819977197005, 0, 1, 1, 0]\n",
      "[20, 9, 9, 0.0, 0, 0, 0, 0]\n",
      "[9, 9, 19, 0.0, 0, 0, 0, 0]\n",
      "[9, 19, 19, 0.0015705154582613227, 0, 0, 0, 0]\n",
      "[19, 19, 20, 0.0050317108250013, 0, 0, 0, 0]\n",
      "[19, 20, 34, 0.009221180445712825, 1, 1, 1, 0]\n",
      "[20, 34, 13, 0.00010178655766004918, 0, 0, 0, 0]\n",
      "[34, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 21, 0.1583991928703548, 0, 1, 1, 0]\n",
      "[20, 21, 8, 0.00047309793127177325, 0, 1, 1, 0]\n",
      "[21, 8, 20, 0, 0, 0, 0, 0]\n",
      "[8, 20, 18, 0.9301310043668122, 1, 1, 1, 1]\n",
      "[20, 18, 33, 4.617970678964836e-06, 0, 0, 0, 0]\n",
      "[18, 33, 13, 0.0, 0, 0, 0, 0]\n",
      "[33, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 19, 0.1583991928703548, 0, 1, 1, 0]\n",
      "[20, 19, 35, 0.02143811694947612, 0, 0, 0, 0]\n",
      "[19, 35, 13, 0.0001578745573874016, 0, 0, 0, 0]\n",
      "[35, 13, 14, 0, 0, 0, 0, 0]\n",
      "[13, 14, 9, 3.779743034169822e-05, 0, 0, 0, 0]\n",
      "[14, 9, 45, 2.376329853594318e-06, 0, 0, 0, 0]\n",
      "Line: 4\n",
      "[45, 20, 34, 1.125, 1, 1, 1, 0]\n",
      "[20, 34, 10, 0, 0, 0, 0, 0]\n",
      "[34, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 19, 0.002620545073375262, 0, 0, 0, 0]\n",
      "[14, 19, 13, 0.0, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 19, 0.001831065784176648, 0, 0, 0, 0]\n",
      "[14, 19, 13, 6.663886217589672e-05, 0, 0, 0, 0]\n",
      "[19, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 4, 0.9758842443729904, 1, 1, 1, 1]\n",
      "[20, 4, 20, 0, 0, 0, 1, 0]\n",
      "[4, 20, 6, 0.22431869227837734, 1, 1, 1, 1]\n",
      "[20, 6, 10, 0, 0, 0, 0, 0]\n",
      "[6, 10, 19, 0, 0, 1, 1, 0]\n",
      "[10, 19, 34, 0.018992502959358146, 0, 0, 0, 0]\n",
      "[19, 34, 36, 0, 0, 0, 0, 0]\n",
      "[34, 36, 13, 0.0001330143803324515, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 9, 0.0002669982382014063, 0, 1, 1, 0]\n",
      "[20, 9, 9, 0.0, 0, 0, 0, 0]\n",
      "[9, 9, 13, 0.0246187387945727, 0, 0, 1, 0]\n",
      "[9, 13, 35, 0, 0, 0, 0, 0]\n",
      "[13, 35, 10, 0.0015748750370894484, 0, 0, 0, 0]\n",
      "[35, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 22, 0.0001700648834500989, 0, 0, 0, 0]\n",
      "[14, 22, 13, 0.00979500573082054, 0, 0, 0, 0]\n",
      "[22, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 20, 0.0, 0, 1, 0, 0]\n",
      "[20, 20, 8, 0.5414364640883977, 1, 1, 1, 0]\n",
      "[20, 8, 20, 0, 0, 0, 0, 0]\n",
      "[8, 20, 25, 0.0, 0, 1, 0, 0]\n",
      "[20, 25, 34, 0, 0, 1, 1, 0]\n",
      "[25, 34, 36, 0, 0, 0, 0, 0]\n",
      "[34, 36, 13, 0.0036518841439755322, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 13, 1.0047619047619047, 1, 1, 1, 1]\n",
      "[20, 13, 9, 0, 0, 0, 0, 0]\n",
      "[13, 9, 20, 0.00108073656353484, 0, 0, 1, 0]\n",
      "[9, 20, 9, 0.000386858308356714, 0, 1, 1, 0]\n",
      "[20, 9, 45, 2.376329853594318e-06, 0, 0, 0, 0]\n",
      "Line: 5\n",
      "[45, 14, 19, 0.11358313817330211, 1, 1, 1, 0]\n",
      "[14, 19, 3, 0.0, 0, 0, 1, 0]\n",
      "[19, 3, 38, 4.03579508089045e-06, 0, 0, 1, 0]\n",
      "[3, 38, 10, 0, 0, 0, 0, 0]\n",
      "[38, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 13, 0.03865449790515838, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 4, 0.5196078431372549, 1, 1, 1, 1]\n",
      "[20, 4, 35, 0, 0, 0, 1, 0]\n",
      "[4, 35, 13, 0.0002293898230706321, 0, 0, 0, 0]\n",
      "[35, 13, 10, 2.5561718769970092e-05, 0, 0, 0, 0]\n",
      "[13, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 19, 0.002089122842774888, 0, 0, 0, 0]\n",
      "[14, 19, 13, 0.003284362198050572, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 8, 0.9311797752808989, 0, 1, 1, 1]\n",
      "[20, 8, 10, 0, 0, 0, 0, 0]\n",
      "[8, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 6, 1.0208333333333333, 1, 1, 1, 1]\n",
      "[20, 6, 10, 0, 0, 0, 0, 0]\n",
      "[6, 10, 14, 0, 0, 1, 1, 0]\n",
      "[10, 14, 19, 0.010045776897855714, 0, 0, 0, 0]\n",
      "[14, 19, 38, 0.042021956472256754, 0, 0, 0, 0]\n",
      "[19, 38, 10, 0, 0, 0, 0, 0]\n",
      "[38, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 19, 0.12588799089559272, 1, 1, 1, 0]\n",
      "[14, 19, 20, 0.0, 0, 0, 0, 0]\n",
      "[19, 20, 4, 0.39676356008390773, 1, 1, 1, 1]\n",
      "[20, 4, 13, 0, 0, 0, 1, 0]\n",
      "[4, 13, 14, 6.495488882970777e-06, 0, 0, 0, 0]\n",
      "[13, 14, 14, 9.17021708257253e-05, 0, 0, 0, 0]\n",
      "[14, 14, 22, 0.0002803729435357404, 0, 0, 0, 0]\n",
      "[14, 22, 37, 0.0016659817357216507, 0, 0, 0, 0]\n",
      "[22, 37, 20, 1.0988545226497464e-05, 0, 0, 0, 0]\n",
      "[37, 20, 4, 0.22829888712241653, 1, 1, 1, 1]\n",
      "[20, 4, 20, 0, 0, 0, 1, 0]\n",
      "[4, 20, 4, 0.4863636363636364, 1, 1, 1, 1]\n",
      "[20, 4, 20, 0, 0, 0, 1, 0]\n",
      "[4, 20, 4, 0.2952755905511811, 1, 1, 1, 1]\n",
      "[20, 4, 20, 0, 0, 0, 1, 0]\n",
      "[4, 20, 4, 0.504, 1, 1, 1, 1]\n",
      "[20, 4, 20, 0, 0, 0, 1, 0]\n",
      "[4, 20, 4, 0.7006960556844548, 1, 1, 1, 1]\n",
      "[20, 4, 20, 0, 0, 0, 1, 0]\n",
      "[4, 20, 4, 0.6666666666666666, 1, 1, 1, 1]\n",
      "[20, 4, 20, 0, 0, 0, 1, 0]\n",
      "[4, 20, 4, 0.11786684782608696, 1, 1, 1, 1]\n",
      "[20, 4, 8, 0, 0, 0, 1, 0]\n",
      "[4, 8, 20, 0, 0, 0, 0, 0]\n",
      "[8, 20, 6, 0.47368421052631576, 1, 1, 1, 1]\n",
      "[20, 6, 45, 0, 0, 0, 0, 0]\n",
      "Line: 6\n",
      "Error #2 on line #6\n",
      "Error #3 on line #7\n",
      "Error #4 on line #8\n",
      "[45, 20, 20, 0.0031924057902471157, 1, 1, 1, 0]\n",
      "[20, 20, 21, 0.00245398773006135, 1, 1, 1, 0]\n",
      "[20, 21, 10, 0.0, 0, 1, 0, 0]\n",
      "[21, 10, 21, 0, 0, 0, 0, 0]\n",
      "[10, 21, 38, 0.024156305506216696, 1, 1, 1, 0]\n",
      "[21, 38, 10, 0, 0, 0, 0, 0]\n",
      "[38, 10, 9, 0, 0, 0, 0, 0]\n",
      "[10, 9, 19, 0.02278268892215287, 1, 0, 1, 0]\n",
      "[9, 19, 19, 0.01808316567950215, 0, 0, 0, 0]\n",
      "[19, 19, 19, 0.032002252357937216, 0, 0, 0, 0]\n",
      "[19, 19, 19, 0.057466834828101644, 0, 0, 0, 0]\n",
      "[19, 19, 39, 0.03200130977418989, 0, 0, 0, 0]\n",
      "[19, 39, 46, 0, 0, 0, 0, 0]\n",
      "[39, 46, 38, 4.255138079230671e-05, 0, 0, 0, 0]\n",
      "[46, 38, 13, 1.8240935395167063e-05, 0, 0, 0, 0]\n",
      "[38, 13, 22, 0, 0, 0, 0, 0]\n",
      "[13, 22, 13, 0.0014600783831553062, 0, 0, 0, 0]\n",
      "[22, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 6, 0.3173076923076923, 0, 0, 0, 1]\n",
      "[19, 6, 25, 0, 0, 0, 0, 0]\n",
      "[6, 25, 38, 0, 0, 1, 1, 0]\n",
      "[25, 38, 46, 0, 0, 0, 0, 0]\n",
      "[38, 46, 36, 4.255138079230671e-05, 0, 0, 0, 0]\n",
      "[46, 36, 13, 1.3229123120803061e-05, 0, 0, 0, 0]\n",
      "[36, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 9, 0, 0, 0, 0, 0]\n",
      "[14, 9, 19, 0, 0, 0, 0, 0]\n",
      "[9, 19, 13, 0.0008491107799082513, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 4, 0.7023460410557185, 1, 1, 1, 1]\n",
      "[20, 4, 8, 0, 0, 0, 1, 0]\n",
      "[4, 8, 34, 0, 0, 0, 0, 0]\n",
      "[8, 34, 36, 0, 0, 0, 0, 0]\n",
      "[34, 36, 13, 1.3229123120803061e-05, 0, 0, 0, 0]\n",
      "[36, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 13, 0.00564324649700699, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 9, 0, 0, 0, 0, 0]\n",
      "[10, 9, 34, 0.022141105891054527, 1, 0, 1, 0]\n",
      "[9, 34, 23, 0.09835120999911355, 0, 0, 0, 0]\n",
      "[34, 23, 10, 0.0, 0, 0, 0, 0]\n",
      "[23, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 20, 0, 0, 0, 1, 0]\n",
      "[20, 20, 34, 0.6, 0, 1, 1, 1]\n",
      "[20, 34, 25, 0, 0, 0, 0, 0]\n",
      "[34, 25, 34, 0, 0, 1, 1, 0]\n",
      "[25, 34, 36, 0, 0, 0, 0, 0]\n",
      "[34, 36, 13, 0.005051016457498198, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 4, 0.5714285714285714, 1, 1, 1, 1]\n",
      "[20, 4, 8, 0, 0, 0, 1, 0]\n",
      "[4, 8, 25, 0, 0, 0, 0, 0]\n",
      "[8, 25, 38, 0, 0, 0, 0, 0]\n",
      "[25, 38, 20, 0.001976739232309462, 0, 0, 0, 0]\n",
      "[38, 20, 20, 0.008333351931244267, 0, 1, 1, 0]\n",
      "[20, 20, 13, 5.058744672509517e-05, 0, 1, 1, 0]\n",
      "[20, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 6, 0.5334255417242969, 1, 1, 1, 1]\n",
      "[20, 6, 25, 0, 0, 0, 0, 0]\n",
      "[6, 25, 46, 0, 0, 1, 1, 0]\n",
      "[25, 46, 38, 5.343504516062842e-06, 0, 0, 0, 0]\n",
      "[46, 38, 10, 4.70937652564177e-06, 0, 0, 0, 0]\n",
      "[38, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 20, 0.0, 1, 0, 0, 0]\n",
      "[14, 20, 35, 1.0714285714285714, 1, 1, 1, 1]\n",
      "[20, 35, 10, 2.4081414445958897e-05, 0, 0, 0, 0]\n",
      "[35, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 13, 0.00048112954412975694, 0, 0, 0, 0]\n",
      "[19, 13, 9, 0, 0, 0, 0, 0]\n",
      "[13, 9, 13, 0.00018172764135629613, 1, 0, 0, 0]\n",
      "[9, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 22, 0.10195381882770871, 1, 1, 1, 0]\n",
      "[14, 22, 8, 0.002691064117901888, 0, 0, 0, 0]\n",
      "[22, 8, 46, 0, 0, 0, 0, 0]\n",
      "[8, 46, 38, 5.343504516062842e-06, 0, 0, 0, 0]\n",
      "[46, 38, 10, 0.002701634547889127, 0, 0, 0, 0]\n",
      "[38, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 14, 0.0007149813398775754, 1, 0, 0, 0]\n",
      "[14, 14, 19, 0.00015666614444618518, 0, 0, 0, 0]\n",
      "[14, 19, 13, 0.0006346823176141404, 0, 0, 0, 0]\n",
      "[19, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 13, 32.0, 0, 1, 1, 1]\n",
      "[20, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 19, 0.009254020114260682, 0, 0, 0, 0]\n",
      "[19, 19, 20, 0.0009975730685049804, 0, 0, 0, 0]\n",
      "[19, 20, 20, 0.0, 0, 0, 0, 0]\n",
      "[20, 20, 38, 0.0007509762691498949, 0, 1, 1, 0]\n",
      "[20, 38, 10, 0.0005815661588699074, 0, 0, 0, 0]\n",
      "[38, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 35, 0.0, 0, 0, 0, 0]\n",
      "[19, 35, 9, 3.4678873630184493e-05, 0, 0, 0, 0]\n",
      "[35, 9, 22, 0.00020751771989347423, 0, 0, 0, 0]\n",
      "[9, 22, 13, 2.3696588876031296e-05, 0, 0, 0, 0]\n",
      "[22, 13, 10, 1.752950012607756e-05, 0, 0, 0, 0]\n",
      "[13, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 14, 0.010461380124005321, 0, 1, 1, 0]\n",
      "[19, 14, 14, 0.0006905800069058, 0, 0, 0, 0]\n",
      "[14, 14, 20, 0, 0, 0, 1, 0]\n",
      "[14, 20, 20, 0.8641975308641975, 0, 1, 1, 1]\n",
      "[20, 20, 46, 0, 0, 0, 1, 0]\n",
      "[20, 46, 34, 5.343504516062842e-06, 0, 0, 0, 0]\n",
      "[46, 34, 10, 1.3229123120803061e-05, 0, 0, 0, 0]\n",
      "[34, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 45, 0.0, 0, 0, 0, 0]\n",
      "Line: 10\n",
      "[45, 20, 34, 1.1884057971014492, 0, 1, 1, 0]\n",
      "[20, 34, 46, 0.0, 0, 0, 0, 0]\n",
      "[34, 46, 36, 0.0002649728592085639, 0, 0, 0, 0]\n",
      "[46, 36, 13, 2.0619003091819515e-05, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 20, 0.019567597153804052, 0, 1, 1, 0]\n",
      "[20, 20, 20, 0.002335067391818397, 0, 1, 1, 0]\n",
      "[20, 20, 20, 0.0018536291612563278, 0, 1, 1, 0]\n",
      "[20, 20, 38, 0.0, 0, 0, 0, 0]\n",
      "[20, 38, 10, 0, 0, 0, 0, 0]\n",
      "[38, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 13, 0.01923247027307075, 0, 0, 0, 0]\n",
      "[19, 13, 19, 0, 0, 0, 0, 0]\n",
      "[13, 19, 13, 0.020357803824799507, 0, 0, 0, 0]\n",
      "[19, 13, 19, 0, 0, 0, 0, 0]\n",
      "[13, 19, 19, 0.030695255384917325, 0, 0, 0, 0]\n",
      "[19, 19, 25, 0.0, 0, 0, 0, 0]\n",
      "[19, 25, 38, 0, 0, 1, 1, 0]\n",
      "[25, 38, 10, 0, 0, 0, 0, 0]\n",
      "[38, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 14, 0.022747156605424323, 0, 0, 0, 0]\n",
      "[14, 14, 14, 0.0, 0, 0, 0, 0]\n",
      "[14, 14, 19, 0.0, 0, 0, 0, 0]\n",
      "[14, 19, 19, 0.048, 0, 0, 0, 1]\n",
      "[19, 19, 39, 0.13636363636363635, 0, 0, 0, 1]\n",
      "[19, 39, 34, 0, 0, 0, 0, 0]\n",
      "[39, 34, 36, 0, 0, 0, 0, 0]\n",
      "[34, 36, 13, 0.004547806048064713, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 9, 0.00037467819977197005, 0, 1, 1, 0]\n",
      "[20, 9, 9, 0.0, 0, 0, 0, 0]\n",
      "[9, 9, 10, 0.0, 0, 0, 0, 0]\n",
      "[9, 10, 19, 0, 0, 1, 1, 0]\n",
      "[10, 19, 38, 1.0, 1, 1, 1, 1]\n",
      "[19, 38, 13, 0, 0, 0, 0, 0]\n",
      "[38, 13, 19, 0, 0, 0, 0, 0]\n",
      "[13, 19, 13, 0.007421500566415894, 0, 0, 0, 0]\n",
      "[19, 13, 35, 0, 0, 0, 0, 0]\n",
      "[13, 35, 8, 0.0001930986541023809, 0, 0, 0, 0]\n",
      "[35, 8, 35, 0, 0, 0, 0, 0]\n",
      "[8, 35, 20, 0.00030567986230636834, 0, 0, 0, 0]\n",
      "[35, 20, 19, 1.1884057971014492, 0, 1, 1, 0]\n",
      "[20, 19, 45, 0.0, 0, 0, 0, 0]\n",
      "Line: 11\n",
      "Error #5 on line #11\n",
      "[45, 19, 38, 0.05196679898953446, 0, 1, 1, 0]\n",
      "[19, 38, 20, 0, 0, 0, 0, 0]\n",
      "[38, 20, 24, 0.013294707981997828, 0, 1, 1, 1]\n",
      "[20, 24, 14, 4.0714739101987575e-06, 0, 0, 1, 0]\n",
      "[24, 14, 22, 0.0020732722316084305, 1, 0, 0, 0]\n",
      "[14, 22, 36, 0.0, 0, 0, 0, 0]\n",
      "[22, 36, 13, 0.00024942072939296777, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 9, 0.00023819051430095848, 0, 1, 1, 0]\n",
      "[20, 9, 13, 0.022698602599474246, 0, 0, 1, 0]\n",
      "[9, 13, 22, 0, 0, 0, 0, 0]\n",
      "[13, 22, 6, 0.9623685666851135, 1, 1, 1, 1]\n",
      "[22, 6, 25, 0, 0, 0, 0, 0]\n",
      "[6, 25, 34, 0, 0, 1, 1, 0]\n",
      "[25, 34, 10, 0, 0, 0, 0, 0]\n",
      "[34, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 46, 0.00012902115947015312, 0, 0, 0, 0]\n",
      "[19, 46, 38, 0.0007149813398775754, 1, 0, 0, 0]\n",
      "[46, 38, 13, 0.040207944677301564, 0, 0, 0, 0]\n",
      "[38, 13, 19, 0, 0, 0, 0, 0]\n",
      "[13, 19, 20, 0.044802271834687775, 0, 0, 0, 0]\n",
      "[19, 20, 8, 0.8648648648648649, 1, 1, 1, 1]\n",
      "[20, 8, 10, 0, 0, 0, 0, 0]\n",
      "[8, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 31, 0.0010893865931699465, 0, 0, 0, 0]\n",
      "[14, 31, 33, 0, 0, 0, 0, 0]\n",
      "[31, 33, 14, 0.000600602189684459, 0, 0, 0, 0]\n",
      "[33, 14, 20, 0.0711835334476844, 0, 0, 0, 0]\n",
      "[14, 20, 6, 0.948051948051948, 1, 1, 1, 1]\n",
      "[20, 6, 45, 0, 0, 0, 0, 0]\n",
      "Line: 13\n",
      "[45, 33, 13, 0.0015614654601633193, 0, 1, 1, 0]\n",
      "[33, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 38, 0.0021145821585654674, 0, 1, 1, 0]\n",
      "[20, 38, 20, 0, 0, 0, 0, 0]\n",
      "[38, 20, 24, 0.013294707981997828, 0, 1, 1, 1]\n",
      "[20, 24, 14, 4.0714739101987575e-06, 0, 0, 1, 0]\n",
      "[24, 14, 19, 0.0018580603993849179, 1, 0, 0, 0]\n",
      "[14, 19, 19, 0.0063889999848122025, 0, 0, 0, 0]\n",
      "[19, 19, 25, 0.0, 0, 0, 0, 0]\n",
      "[19, 25, 34, 0, 0, 1, 1, 0]\n",
      "[25, 34, 36, 0, 0, 0, 0, 0]\n",
      "[34, 36, 13, 0.00024942072939296777, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 9, 0.00023819051430095848, 0, 1, 1, 0]\n",
      "[20, 9, 13, 0.024591812921967666, 0, 0, 1, 0]\n",
      "[9, 13, 22, 0, 0, 0, 0, 0]\n",
      "[13, 22, 6, 0.9623685666851135, 1, 1, 1, 1]\n",
      "[22, 6, 45, 0, 0, 0, 0, 0]\n",
      "Line: 14\n",
      "Error #6 on line #14\n",
      "[45, 20, 38, 0.00016695021703528215, 0, 1, 1, 0]\n",
      "[20, 38, 10, 0, 0, 0, 0, 0]\n",
      "[38, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 13, 0.0028807127141050005, 0, 0, 0, 0]\n",
      "[19, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 24, 0.013294707981997828, 0, 1, 1, 1]\n",
      "[20, 24, 14, 4.0714739101987575e-06, 0, 0, 1, 0]\n",
      "[24, 14, 14, 0.0007149813398775754, 1, 0, 0, 0]\n",
      "[14, 14, 19, 0.0017708320433915768, 0, 0, 0, 0]\n",
      "[14, 19, 36, 0.0, 0, 0, 0, 0]\n",
      "[19, 36, 13, 1.2789616293240322e-05, 0, 1, 1, 0]\n",
      "[36, 13, 26, 6.623443963771654e-06, 0, 0, 0, 0]\n",
      "[13, 26, 19, 0, 0, 0, 0, 0]\n",
      "[26, 19, 13, 0.0011289807221216317, 0, 1, 1, 0]\n",
      "[19, 13, 25, 0.0, 0, 0, 0, 0]\n",
      "[13, 25, 34, 0, 0, 0, 0, 0]\n",
      "[25, 34, 36, 0, 0, 0, 0, 0]\n",
      "[34, 36, 13, 0.00024942072939296777, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 9, 0.0003481528926818708, 0, 1, 1, 0]\n",
      "[20, 9, 13, 0.022380720117061, 0, 0, 1, 0]\n",
      "[9, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 38, 0.9623685666851135, 1, 1, 1, 1]\n",
      "[20, 38, 10, 0.0, 0, 0, 0, 0]\n",
      "[38, 10, 19, 0, 0, 1, 1, 0]\n",
      "[10, 19, 34, 0.040207944677301564, 0, 0, 0, 0]\n",
      "[19, 34, 13, 8.658233547191702e-06, 0, 0, 0, 0]\n",
      "[34, 13, 31, 0, 0, 0, 0, 0]\n",
      "[13, 31, 33, 0, 0, 0, 0, 0]\n",
      "[31, 33, 9, 0.00022330685552046447, 0, 0, 0, 0]\n",
      "[33, 9, 9, 0.00013642918843169457, 0, 0, 0, 0]\n",
      "[9, 9, 19, 0.0011491020129374423, 0, 0, 0, 0]\n",
      "[9, 19, 35, 0.0, 0, 0, 0, 0]\n",
      "[19, 35, 19, 4.823461315840247e-05, 0, 0, 0, 0]\n",
      "[35, 19, 9, 0, 0, 1, 1, 0]\n",
      "[19, 9, 13, 0.0016658127210667142, 1, 0, 1, 0]\n",
      "[9, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 22, 0.06107003491476689, 0, 0, 0, 1]\n",
      "[19, 22, 37, 0.001256390110859987, 0, 0, 0, 0]\n",
      "[22, 37, 45, 0.0, 0, 0, 0, 0]\n",
      "Line: 16\n",
      "Error #7 on line #16\n",
      "[45, 20, 20, 0.9565217391304348, 1, 1, 1, 0]\n",
      "[20, 20, 20, 0, 0, 0, 0, 0]\n",
      "[20, 20, 46, 0.0, 0, 0, 0, 0]\n",
      "[20, 46, 36, 0.0002649728592085639, 0, 0, 0, 0]\n",
      "[46, 36, 13, 2.0619003091819515e-05, 0, 0, 0, 0]\n",
      "[36, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 8, 0.0, 1, 1, 0, 0]\n",
      "[20, 8, 20, 0, 0, 0, 0, 0]\n",
      "[8, 20, 38, 0.0, 0, 1, 0, 0]\n",
      "[20, 38, 10, 0, 0, 0, 0, 0]\n",
      "[38, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 13, 0.026680316068972136, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 19, 0.489247311827957, 1, 1, 1, 1]\n",
      "[20, 19, 13, 0.03865449790515838, 0, 0, 0, 0]\n",
      "[19, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 4, 0.9758842443729904, 1, 1, 1, 1]\n",
      "[20, 4, 20, 0, 0, 0, 1, 0]\n",
      "[4, 20, 6, 0.22431869227837734, 1, 1, 1, 1]\n",
      "[20, 6, 25, 0, 0, 0, 0, 0]\n",
      "[6, 25, 38, 0, 0, 1, 1, 0]\n",
      "[25, 38, 36, 0, 0, 0, 0, 0]\n",
      "[38, 36, 13, 0.00011871604036345373, 0, 0, 0, 0]\n",
      "[36, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 22, 0, 0, 0, 0, 0]\n",
      "[10, 22, 13, 0.0006824197200165821, 0, 0, 0, 0]\n",
      "[22, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 19, 0.6649484536082474, 0, 1, 1, 1]\n",
      "[20, 19, 46, 0.0, 0, 0, 0, 0]\n",
      "[19, 46, 9, 0.00017376014357256043, 0, 0, 0, 0]\n",
      "[46, 9, 22, 0.0010877431712697126, 1, 0, 1, 0]\n",
      "[9, 22, 13, 0.008637230983474985, 0, 0, 0, 0]\n",
      "[22, 13, 26, 5.5698094051005925e-06, 0, 0, 0, 0]\n",
      "[13, 26, 19, 3.280320917440154e-05, 0, 0, 0, 0]\n",
      "[26, 19, 13, 0.024984436605104795, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 22, 0, 0, 0, 0, 0]\n",
      "[10, 22, 20, 0, 0, 0, 0, 0]\n",
      "[22, 20, 10, 0, 0, 1, 0, 0]\n",
      "[20, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 19, 0.006903359590833504, 0, 0, 0, 0]\n",
      "[14, 19, 13, 6.663886217589672e-05, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 6, 1.0, 1, 1, 1, 1]\n",
      "[20, 6, 20, 0, 0, 0, 0, 0]\n",
      "[6, 20, 38, 0.9565217391304348, 1, 1, 1, 0]\n",
      "[20, 38, 10, 3.7008138706503874e-06, 0, 0, 0, 0]\n",
      "[38, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 13, 0.02084842100643009, 0, 0, 0, 0]\n",
      "[19, 13, 9, 0, 0, 0, 0, 0]\n",
      "[13, 9, 22, 0.0, 1, 0, 0, 0]\n",
      "[9, 22, 8, 0.0002937202608235916, 0, 0, 0, 0]\n",
      "[22, 8, 34, 0, 0, 0, 0, 0]\n",
      "[8, 34, 10, 0, 0, 0, 0, 0]\n",
      "[34, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 13, 0.01940950899680888, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 20, 0.0001700648834500989, 0, 0, 0, 0]\n",
      "[14, 20, 19, 1.125, 1, 1, 1, 1]\n",
      "[20, 19, 13, 0.0, 0, 0, 0, 0]\n",
      "[19, 13, 20, 7.0256393683107135e-06, 0, 1, 1, 0]\n",
      "[13, 20, 9, 0.000386858308356714, 0, 1, 1, 0]\n",
      "[20, 9, 25, 2.376329853594318e-06, 0, 0, 0, 0]\n",
      "[9, 25, 38, 0, 0, 0, 0, 0]\n",
      "[25, 38, 19, 0, 0, 0, 0, 0]\n",
      "[38, 19, 13, 6.663886217589672e-05, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 20, 0.018992502959358146, 0, 0, 0, 0]\n",
      "[19, 20, 6, 1.0047619047619047, 0, 1, 1, 1]\n",
      "[20, 6, 45, 0, 0, 0, 0, 0]\n",
      "Line: 18\n",
      "Error #8 on line #18\n",
      "[45, 20, 19, 0.08333333333333333, 0, 1, 1, 1]\n",
      "[20, 19, 34, 0.00018525206291404345, 0, 0, 0, 0]\n",
      "[19, 34, 14, 7.128305216921456e-06, 0, 0, 0, 0]\n",
      "[34, 14, 22, 0.005296124662626674, 0, 0, 0, 0]\n",
      "[14, 22, 13, 0.00324817663704117, 0, 0, 0, 0]\n",
      "[22, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 20, 0.15434596350682592, 0, 1, 1, 0]\n",
      "[14, 20, 13, 0.019779703439987712, 0, 1, 1, 0]\n",
      "[20, 13, 20, 0, 0, 0, 0, 0]\n",
      "[13, 20, 20, 0.0006886833971496371, 0, 1, 1, 0]\n",
      "[20, 20, 20, 0.0014436185634489433, 0, 1, 1, 0]\n",
      "[20, 20, 20, 1.7412562815820358e-06, 0, 1, 1, 0]\n",
      "[20, 20, 18, 0.08333333333333333, 0, 1, 1, 0]\n",
      "[20, 18, 46, 1.8207689653571393e-06, 0, 0, 0, 0]\n",
      "[18, 46, 33, 5.343504516062842e-06, 0, 0, 0, 0]\n",
      "[46, 33, 19, 2.0597129509132954e-05, 0, 0, 0, 0]\n",
      "[33, 19, 45, 0, 0, 0, 0, 0]\n",
      "Line: 20\n",
      "[45, 14, 19, 0.13822791244400673, 1, 1, 1, 0]\n",
      "[14, 19, 38, 0.02154460400806956, 0, 0, 0, 0]\n",
      "[19, 38, 8, 6.623876424961416e-06, 0, 0, 0, 0]\n",
      "[38, 8, 10, 2.5449280254171337e-05, 0, 0, 0, 0]\n",
      "[8, 10, 22, 0, 0, 0, 0, 0]\n",
      "[10, 22, 36, 0.0008690089676897638, 0, 0, 0, 0]\n",
      "[22, 36, 13, 0.00035954907015078933, 0, 0, 0, 0]\n",
      "[36, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 20, 9.025075269127744e-06, 0, 0, 0, 0]\n",
      "[10, 20, 19, 0.0017473075578994185, 1, 1, 1, 0]\n",
      "[20, 19, 13, 0.0, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 19, 0, 0, 0, 0, 0]\n",
      "[10, 19, 25, 0.013041743442141554, 0, 0, 0, 0]\n",
      "[19, 25, 37, 0, 0, 0, 0, 0]\n",
      "[25, 37, 8, 0.0, 0, 0, 0, 0]\n",
      "[37, 8, 10, 0, 0, 0, 0, 0]\n",
      "[8, 10, 22, 0, 0, 0, 0, 0]\n",
      "[10, 22, 13, 0.0003080398398192833, 0, 0, 0, 0]\n",
      "[22, 13, 10, 2.5561718769970092e-05, 0, 0, 0, 0]\n",
      "[13, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 14, 0.00013070851275497238, 0, 0, 0, 0]\n",
      "[14, 14, 19, 0.00932840576016312, 0, 0, 0, 0]\n",
      "[14, 19, 10, 0.0, 0, 0, 0, 0]\n",
      "[19, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 20, 0.068, 0, 1, 1, 0]\n",
      "[20, 20, 8, 0.3008028098344205, 1, 1, 1, 1]\n",
      "[20, 8, 10, 0, 0, 0, 0, 0]\n",
      "[8, 10, 20, 0, 0, 0, 0, 0]\n",
      "[10, 20, 20, 0.011627906976744186, 1, 1, 0, 0]\n",
      "[20, 20, 6, 0.06862745098039216, 0, 1, 1, 1]\n",
      "[20, 6, 16, 0, 0, 0, 0, 0]\n",
      "[6, 16, 21, 0.0001905148133623302, 0, 1, 1, 0]\n",
      "[16, 21, 37, 0.0017473075578994185, 0, 1, 1, 0]\n",
      "[21, 37, 26, 0.00024023401619459897, 0, 0, 0, 0]\n",
      "[37, 26, 19, 0, 0, 0, 0, 0]\n",
      "[26, 19, 13, 0.02154460400806956, 0, 0, 0, 0]\n",
      "[19, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 14, 0, 0, 0, 0, 0]\n",
      "[10, 14, 19, 0.020695929042528996, 0, 0, 0, 0]\n",
      "[14, 19, 13, 6.663886217589672e-05, 0, 0, 0, 0]\n",
      "[19, 13, 14, 0, 0, 0, 0, 0]\n",
      "[13, 14, 19, 0.006194613646583047, 1, 1, 1, 0]\n",
      "[14, 19, 20, 0.0, 0, 0, 0, 0]\n",
      "[19, 20, 22, 0.0, 0, 1, 0, 0]\n",
      "[20, 22, 13, 0.000665881202147854, 0, 0, 0, 0]\n",
      "[22, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 13, 0.0, 0, 0, 0, 0]\n",
      "[10, 13, 10, 0, 0, 0, 0, 0]\n",
      "[13, 10, 9, 0, 0, 0, 0, 0]\n",
      "[10, 9, 14, 0.00013642918843169457, 1, 0, 0, 0]\n",
      "[9, 14, 14, 0.00013070851275497238, 0, 0, 0, 0]\n",
      "[14, 14, 22, 0.04749530821423416, 0, 0, 0, 0]\n",
      "[14, 22, 46, 0.0007513655435580957, 0, 0, 0, 0]\n",
      "[22, 46, 37, 5.625056250562505e-06, 0, 0, 0, 0]\n",
      "[46, 37, 26, 0.00012193577736402988, 0, 0, 0, 0]\n",
      "[37, 26, 14, 0, 0, 0, 0, 0]\n",
      "[26, 14, 22, 0.00932840576016312, 0, 0, 0, 0]\n",
      "[14, 22, 13, 0.0001395328868280955, 0, 0, 0, 0]\n",
      "[22, 13, 13, 5.5698094051005925e-06, 0, 0, 0, 0]\n",
      "[13, 13, 26, 0.0, 0, 0, 0, 0]\n",
      "[13, 26, 14, 0, 0, 0, 0, 0]\n",
      "[26, 14, 19, 3.599218455421108e-05, 0, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c13e2e1673b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mAppend\u001b[0m \u001b[0mmention\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mnewData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmentionProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \"\"\"\n",
      "\u001b[0;32m/users/cs/amaral/wikisim/wikification/wikification.pyc\u001b[0m in \u001b[0;36mmentionProb\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mtotalMentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mention_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mtotalAppearances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_solr_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotalAppearances\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/wikisim/wikification/wikification.pyc\u001b[0m in \u001b[0;36mget_solr_count\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mqstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://localhost:8983/solr/enwiki20160305/select'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'indent'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'on'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rows'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'response'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    486\u001b[0m         }\n\u001b[1;32m    487\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/site-packages/requests/adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    421\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m                 )\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, **response_kw)\u001b[0m\n\u001b[1;32m    592\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self, buffering)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwill_close\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_UNKNOWN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CS_IDLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Initialize with Simple-Response defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/cs/amaral/anaconda2/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%writefile gen-mention-data.py\n",
    "\n",
    "\"\"\"\n",
    "Generate data to be used for entity recognition.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Mention Data of form [pos before, pos on, pos after, mentions prob].\n",
    "[0:3] are to be One Hot Encoded.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from wikification import *\n",
    "from wikipedia import title2id\n",
    "import copy\n",
    "import sys\n",
    "import copy\n",
    "import nltk\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "scnlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "# need this for novelty detection\n",
    "#from sklearn.svm import OneClassSVM\n",
    "\n",
    "# for pos on pos parts\n",
    "#ohe = OneHotEncoder(n_values=[46,46,46])\n",
    "\n",
    "# convert pos values to numbers\n",
    "posDict = {\n",
    "    \"$\":0,\n",
    "    \"''\":1,\n",
    "    \"(\":2,\n",
    "    \")\":3,\n",
    "    \",\":4,\n",
    "    \"--\":5,\n",
    "    \".\":6,\n",
    "    \":\":7,\n",
    "    \"CC\":8,\n",
    "    \"CD\":9,\n",
    "    \"DT\":10,\n",
    "    \"EX\":11,\n",
    "    \"FW\":12,\n",
    "    \"IN\":13,\n",
    "    \"JJ\":14,\n",
    "    \"JJR\":15,\n",
    "    \"JJS\":16,\n",
    "    \"LS\":17,\n",
    "    \"MD\":18,\n",
    "    \"NN\":19,\n",
    "    \"NNP\":20,\n",
    "    \"NNPS\":21,\n",
    "    \"NNS\":22,\n",
    "    \"PDT\":23,\n",
    "    \"POS\":24,\n",
    "    \"PRP\":25,\n",
    "    \"PRP$\":26,\n",
    "    \"RBR\":27,\n",
    "    \"RBS\":28,\n",
    "    \"RP\":29,\n",
    "    \"SYM\":30,\n",
    "    \"TO\":31,\n",
    "    \"UH\":32,\n",
    "    \"VB\":33,\n",
    "    \"VBD\":34,\n",
    "    \"VBG\":35,\n",
    "    \"VBN\":36,\n",
    "    \"VBP\":37,\n",
    "    \"VBZ\":38,\n",
    "    \"WDT\":39,\n",
    "    \"WP\":40,\n",
    "    \"WP$\":41,\n",
    "    \"WRB\":42,\n",
    "    \"``\":43,\n",
    "    \"None\":44,\n",
    "    \"NONE\":45,\n",
    "    \"RB\":46\n",
    "}\n",
    "\n",
    "def normalize(nums):\n",
    "    \"\"\"Normalizes a list of nums to its sum + 1\"\"\"\n",
    "    \n",
    "    numSum = sum(nums) + 1 # get max\n",
    "    \n",
    "    # fill with normalized\n",
    "    normNums = []\n",
    "    for num in nums:\n",
    "        normNums.append(num/numSum)\n",
    "        \n",
    "    return normNums\n",
    "\n",
    "pathStrt = '/users/cs/amaral/wsd-datasets'\n",
    "dsPath = os.path.join(pathStrt,'wiki-mentions.30000.json')\n",
    "\n",
    "newData = []\n",
    "\n",
    "# exclude non-mentions to treat as novelty detection\n",
    "# include non-mentions to treat as classification\n",
    "nonMentions = True\n",
    "\n",
    "with open(dsPath, 'r') as dataFile:\n",
    "    dataLines = []\n",
    "    skip = 3\n",
    "    amount = 100\n",
    "    i = 0\n",
    "    for line in dataFile:\n",
    "        if i >= skip:\n",
    "            dataLines.append(json.loads(line.decode('utf-8').strip()))\n",
    "        i += 1\n",
    "        if i >= skip + amount:\n",
    "            break\n",
    "            \n",
    "errors = 0\n",
    "        \n",
    "lnum = 0\n",
    "for line in dataLines:\n",
    "    \n",
    "    oMentions = copy.deepcopy(line['mentions']) # mentions in original form\n",
    "    oText = \" \".join(copy.deepcopy(line['text']))\n",
    "    #uni = unicode(oText, 'utf-8')\n",
    "    #print uni\n",
    "    line['mentions'] = mentionStartsAndEnds(line, True)\n",
    "\n",
    "    #Get POS tags of all text\n",
    "    postrs = nltk.pos_tag(copy.deepcopy(line['text']))\n",
    "\n",
    "    # get stanford core mentions\n",
    "    try:\n",
    "        stnfrdMentions0 = scnlp.annotate(oText.encode('utf-8'), properties={\n",
    "                'annotators': 'entitymentions',\n",
    "                'outputFormat': 'json'})\n",
    "    except:\n",
    "        errors += 1\n",
    "        print 'Error #' + str(errors) + ' on line #' + str(lnum)\n",
    "        lnum += 1\n",
    "        continue\n",
    "    stnfrdMentions = []\n",
    "    for sentence in stnfrdMentions0['sentences']:\n",
    "        for mention in sentence['entitymentions']:\n",
    "            stnfrdMentions.append(mention['text'])\n",
    "\n",
    "    for i in range(len(line['text'])):\n",
    "        \n",
    "        if nonMentions == False and i not in [item[0] for item in oMentions]:\n",
    "            continue\n",
    "        \n",
    "        newData.append([]) # add new row to mention data at mIdx\n",
    "             \n",
    "        \"\"\" \n",
    "        Append POS tags of before, on, and after mention.\n",
    "        \"\"\"\n",
    "        if i == 0:\n",
    "            bef = posDict['NONE']\n",
    "        else:\n",
    "            bef = posDict[postrs[i-1][1]] # pos tag of before\n",
    "            \n",
    "        on = posDict[postrs[i][1]] # pos tag of mention\n",
    "        \n",
    "        if i == len(line['text']) - 1:\n",
    "            aft = posDict['NONE']\n",
    "        else:\n",
    "            aft = posDict[postrs[i+1][1]] # pos tag of after\n",
    "        \n",
    "        newData[-1].extend([bef, on, aft])\n",
    "        \n",
    "        \"\"\"\n",
    "        Append mention probability.\n",
    "        \"\"\"\n",
    "        newData[-1].append(mentionProb(line['text'][i]))\n",
    "        \n",
    "        \"\"\"\n",
    "        Find whether Stanford NER decides the word to be mention.\n",
    "        \"\"\"\n",
    "        if line['text'][i] in stnfrdMentions:\n",
    "            stnfrdMentions.remove(line['text'][i])\n",
    "            newData[-1].append(1)\n",
    "        else:\n",
    "            newData[-1].append(0)\n",
    "            \n",
    "        \"\"\"\n",
    "        Whether starts with capital.\n",
    "        \"\"\"\n",
    "        if line['text'][i][0].isupper():\n",
    "            newData[-1].append(1)\n",
    "        else:\n",
    "            newData[-1].append(0)\n",
    "            \n",
    "        \"\"\"\n",
    "        Whether there is an exact match in Wikipedia.\n",
    "        \"\"\"\n",
    "        if title2id(line['text'][i]) is not None:\n",
    "            newData[-1].append(1)\n",
    "        else:\n",
    "            newData[-1].append(0)\n",
    "        \n",
    "        # put in whether is mention or not only if including nonMentions\n",
    "        if nonMentions == True:\n",
    "            if i in [item[0] for item in oMentions]:\n",
    "                newData[-1].append(1)\n",
    "            else:\n",
    "                newData[-1].append(0)\n",
    "    \n",
    "        print newData[-1]\n",
    "        \n",
    "    lnum += 1\n",
    "    print 'Line: ' + str(lnum)\n",
    "    \n",
    "# nov for novelty, cls for classification\n",
    "#with open('/use1rs/cs/amaral/wikisim/wikification/learning-data/er-10000-nov.txt', 'w') as f:\n",
    "#with open('/use1rs/cs/amaral/wikisim/wikification/learning-data/er-10000-cls.txt', 'w') as f:\n",
    "    # do the thingstanford-corenlp-full-2017-06-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model-create.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model-create.py \n",
    "\n",
    "\"\"\"\n",
    "Train model and everything here in a script because ssh and jupyter are failing me.\n",
    "\"\"\"\n",
    "\n",
    "allX = []\n",
    "allY = []\n",
    "allMId = []\n",
    "\n",
    "\n",
    "trainX = []\n",
    "trainY = []\n",
    "trainMId = []\n",
    "\n",
    "bigTrainX = []\n",
    "bigTrainY = []\n",
    "bigTrainMId = []\n",
    "\n",
    "valiX = []\n",
    "valiY = []\n",
    "valiMId = []\n",
    "\n",
    "testX = []\n",
    "testY = []\n",
    "testMId = []\n",
    "\n",
    "\n",
    "linesToUse = 10000000 # limit amount of total data\n",
    "totalLines = 0\n",
    "# first try with just getting all data\n",
    "with open('/users/cs/amaral/wikisim/wikification/learning-data/el-10000-hybridgen.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        totalLines += 1\n",
    "        if totalLines > linesToUse:\n",
    "            break\n",
    "        data = line.split(',')\n",
    "        allX.append([float(data[2]), float(data[3]), float(data[4]), float(data[5]), float(data[6])])\n",
    "        allY.append(int(data[1]))\n",
    "        allMId.append(long(data[7]))\n",
    "        \n",
    "# split 60,20,20 or 80,20 with bigTrain\n",
    "trainLines = int(totalLines * 0.6)\n",
    "valiLines = int(totalLines * 0.2)\n",
    "testLines = int(totalLines * 0.2)\n",
    "\n",
    "for i in range(0, trainLines):\n",
    "    trainX.append(allX[i])\n",
    "    trainY.append(allY[i])\n",
    "    trainMId.append(allMId[i])\n",
    "    \n",
    "for i in range(0, trainLines + valiLines):\n",
    "    bigTrainX.append(allX[i])\n",
    "    bigTrainY.append(allY[i])\n",
    "    bigTrainMId.append(allMId[i])\n",
    "\n",
    "for i in range(trainLines, trainLines + valiLines):\n",
    "    valiX.append(allX[i])\n",
    "    valiY.append(allY[i])\n",
    "    valiMId.append(allMId[i])\n",
    "    \n",
    "for i in range(trainLines + valiLines, trainLines + valiLines + testLines):\n",
    "    testX.append(allX[i])\n",
    "    testY.append(allY[i])\n",
    "    testMId.append(allMId[i])\n",
    "    \n",
    "print 'about to start training'\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "#from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sys\n",
    "sys.path.append('./pyltr/')\n",
    "import pyltr\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=300)\n",
    "abc.fit(bigTrainX, bigTrainY)\n",
    "\n",
    "print 'adaboost done'\n",
    "\n",
    "bgc = BaggingClassifier(verbose=1, n_estimators=300)\n",
    "bgc.fit(bigTrainX, bigTrainY)\n",
    "\n",
    "print 'bagging done'\n",
    "\n",
    "etc = ExtraTreesClassifier(verbose=1, n_estimators=300, min_samples_split=5)\n",
    "etc.fit(bigTrainX, bigTrainY)\n",
    "\n",
    "print 'extra trees done'\n",
    "\n",
    "gbc = GradientBoostingClassifier(verbose=1, n_estimators=300, min_samples_split=5)\n",
    "gbc.fit(bigTrainX, bigTrainY)\n",
    "\n",
    "print 'gradient boosting done'\n",
    "\n",
    "rfc = RandomForestClassifier(verbose=1, n_estimators=300, min_samples_split=5)\n",
    "rfc.fit(bigTrainX, bigTrainY)\n",
    "\n",
    "print 'random forest done'\n",
    "\n",
    "\"\"\"lsvc = LinearSVC(verbose=1)\n",
    "lsvc.fit(bigTrainX, bigTrainY)\n",
    "\n",
    "print 'linear svc done'\n",
    "\n",
    "#nsvc = NuSVC(verbose=True)\n",
    "#nsvc.fit(bigTrainX, bigTrainY)\n",
    "\n",
    "#print 'nusvc done'\n",
    "\n",
    "svc = SVC(verbose=True)\n",
    "svc.fit(bigTrainX, bigTrainY)\n",
    "\n",
    "print 'svc done'\n",
    "\n",
    "monitor = pyltr.models.monitors.ValidationMonitor(\n",
    "    valiX, valiY, valiMId, metric=pyltr.metrics.NDCG(k=10), stop_after=250)\n",
    "lmart = pyltr.models.LambdaMART(n_estimators=300, learning_rate=0.1, verbose = 1)\n",
    "lmart.fit(trainX, trainY, trainMId, monitor=monitor)\n",
    "\n",
    "print 'lmart done'\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Save the model.\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(abc, open('/users/cs/amaral/wikisim/wikification/ml-models/model-abc-10000-hyb.pkl', 'wb'))\n",
    "pickle.dump(bgc, open('/users/cs/amaral/wikisim/wikification/ml-models/model-bgc-10000-hyb.pkl', 'wb'))\n",
    "pickle.dump(etc, open('/users/cs/amaral/wikisim/wikification/ml-models/model-etc-10000-hyb.pkl', 'wb'))\n",
    "pickle.dump(gbc, open('/users/cs/amaral/wikisim/wikification/ml-models/model-gbc-10000-hyb.pkl', 'wb'))\n",
    "pickle.dump(rfc, open('/users/cs/amaral/wikisim/wikification/ml-models/model-rfc-10000-hyb.pkl', 'wb'))\n",
    "#pickle.dump(lsvc, open('/users/cs/amaral/wikisim/wikification/ml-models/model-lsvc-10000-pop.pkl', 'wb'))\n",
    "#pickle.dump(nsvc, open('/users/cs/amaral/wikisim/wikification/ml-models/model-nsvc-10000-hyb.pkl', 'wb'))\n",
    "#pickle.dump(svc, open('/users/cs/amaral/wikisim/wikification/ml-models/model-svc-10000-pop.pkl', 'wb'))\n",
    "#pickle.dump(lmart, open('/users/cs/amaral/wikisim/wikification/ml-models/model-lmart-10000-pop.pkl', 'wb'))\n",
    "\n",
    "print 'models saved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 170097\n",
      "56699\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell is to get all the data for the ml model\n",
    "\"\"\"\n",
    "\n",
    "allX = []\n",
    "allY = []\n",
    "allMId = []\n",
    "\n",
    "trainX = []\n",
    "trainY = []\n",
    "trainMId = []\n",
    "valiX = []\n",
    "valiY = []\n",
    "valiMId = []\n",
    "testX = []\n",
    "testY = []\n",
    "testMId = []\n",
    "\n",
    "linesToUse = 1000000 # limit amount of total data\n",
    "totalLines = 0\n",
    "# first try with just getting all data\n",
    "with open('/users/cs/amaral/wikisim/wikification/learning-data/el-5000.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        totalLines += 1\n",
    "        if totalLines > linesToUse:\n",
    "            break\n",
    "        data = line.split(',')\n",
    "        allX.append([float(data[2]), float(data[3]), float(data[4]), float(data[5]), float(data[6])])\n",
    "        allY.append(int(data[1]))\n",
    "        allMId.append(long(data[7]))\n",
    "        \n",
    "# split 75, 25\n",
    "trainLines = int(totalLines * 0.75)\n",
    "valiLines = int(totalLines * 0.0)\n",
    "testLines = int(totalLines * 0.25)\n",
    "\n",
    "for i in range(0, trainLines):\n",
    "    trainX.append(allX[i])\n",
    "    trainY.append(allY[i])\n",
    "    trainMId.append(allMId[i])\n",
    "\n",
    "for i in range(trainLines, trainLines + valiLines):\n",
    "    valiX.append(allX[i])\n",
    "    valiY.append(allY[i])\n",
    "    valiMId.append(allMId[i])\n",
    "    \n",
    "for i in range(trainLines + valiLines, trainLines + valiLines + testLines):\n",
    "    testX.append(allX[i])\n",
    "    testY.append(allY[i])\n",
    "    testMId.append(allMId[i])\n",
    "    \n",
    "print len(trainX)\n",
    "print len(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.8987       88.16m                                         \n",
      "    2       0.9178       86.97m                                         \n",
      "    3       0.9288       86.27m                                         \n",
      "    4       0.9290       85.70m                                         \n",
      "    5       0.9356       85.35m                                         \n",
      "    6       0.9362       84.96m                                         \n",
      "    7       0.9387       84.65m                                         \n",
      "    8       0.9411       84.34m                                         \n",
      "    9       0.9412       84.02m                                         \n",
      "   10       0.9414       83.73m                                         \n",
      "   15       0.9439       82.20m                                         \n",
      "   20       0.9479       80.73m                                         \n",
      "   25       0.9519       79.28m                                         \n",
      "   30       0.9546       77.82m                                         \n",
      "   35       0.9556       76.38m                                         \n",
      "   40       0.9571       74.97m                                         \n",
      "   45       0.9580       73.55m                                         \n",
      "   50       0.9585       72.14m                                         \n"
     ]
    }
   ],
   "source": [
    "\"\"\" This cell helped by: https://github.com/ogrisel/notebooks/blob/master/Learning%20to%20Rank.ipynb\n",
    "This cell is to train the model.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "sys.path.append('./pyltr/')\n",
    "import pyltr\n",
    "\n",
    "#etr = ExtraTreesRegressor(n_estimators=200, min_samples_split=5, random_state=1, n_jobs=-1)\n",
    "#etr.fit(trainX, trainY)\n",
    "\n",
    "#rfr = RandomForestRegressor(n_estimators=200, min_samples_split=5, random_state=1, n_jobs=-1)\n",
    "#rfr.fit(trainX, trainY)\n",
    "\n",
    "#gbr = GradientBoostingRegressor(n_estimators=300, max_depth=3, learning_rate=0.1, loss='ls', random_state=1)\n",
    "#gbr.fit(trainX, trainY)\n",
    "\n",
    "#gbc = GradientBoostingClassifier(n_estimators=200, min_samples_split=5, random_state=1)\n",
    "#gbc.fit(trainX, trainY)\n",
    "\n",
    "lmart = pyltr.models.LambdaMART(n_estimators=300, learning_rate=0.1, verbose = 1)\n",
    "lmart.fit(trainX, trainY, trainMId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Regressor:\n",
      "R^2 Score: 0.843993888891\n",
      "\n",
      "BDB =  0.0 \n",
      "TP: 6134 0.993199481865 \n",
      "FP: 8991 0.17795855353 \n",
      "TN: 41532 0.82204144647 \n",
      "FN: 42 0.00680051813472\n",
      "\n",
      "BDB =  0.1 \n",
      "TP: 5993 0.970369170984 \n",
      "FP: 1909 0.0377847712923 \n",
      "TN: 48614 0.962215228708 \n",
      "FN: 183 0.0296308290155\n",
      "\n",
      "BDB =  0.2 \n",
      "TP: 5897 0.954825129534 \n",
      "FP: 1204 0.0238307305584 \n",
      "TN: 49319 0.976169269442 \n",
      "FN: 279 0.0451748704663\n",
      "\n",
      "BDB =  0.3 \n",
      "TP: 5788 0.937176165803 \n",
      "FP: 878 0.0173782237793 \n",
      "TN: 49645 0.982621776221 \n",
      "FN: 388 0.0628238341969\n",
      "\n",
      "BDB =  0.4 \n",
      "TP: 5679 0.919527202073 \n",
      "FP: 667 0.0132019080419 \n",
      "TN: 49856 0.986798091958 \n",
      "FN: 497 0.0804727979275\n",
      "\n",
      "BDB =  0.5 \n",
      "TP: 5533 0.895887305699 \n",
      "FP: 496 0.0098173109277 \n",
      "TN: 50027 0.990182689072 \n",
      "FN: 643 0.104112694301\n",
      "\n",
      "BDB =  0.6 \n",
      "TP: 5372 0.86981865285 \n",
      "FP: 374 0.00740256912693 \n",
      "TN: 50149 0.992597430873 \n",
      "FN: 804 0.13018134715\n",
      "\n",
      "BDB =  0.7 \n",
      "TP: 5177 0.838244818653 \n",
      "FP: 270 0.00534410070661 \n",
      "TN: 50253 0.994655899293 \n",
      "FN: 999 0.161755181347\n",
      "\n",
      "BDB =  0.8 \n",
      "TP: 4894 0.792422279793 \n",
      "FP: 174 0.00344397601093 \n",
      "TN: 50349 0.996556023989 \n",
      "FN: 1282 0.207577720207\n",
      "\n",
      "BDB =  0.9 \n",
      "TP: 4462 0.722474093264 \n",
      "FP: 91 0.00180115986778 \n",
      "TN: 50432 0.998198840132 \n",
      "FN: 1714 0.277525906736\n",
      "\n",
      "\n",
      "Random Forest Regressor:\n",
      "R^2 Score: 0.84456202897\n",
      "\n",
      "BDB =  0.0 \n",
      "TP: 6122 0.991256476684 \n",
      "FP: 6381 0.126298913366 \n",
      "TN: 44142 0.873701086634 \n",
      "FN: 54 0.00874352331606\n",
      "\n",
      "BDB =  0.1 \n",
      "TP: 5994 0.970531088083 \n",
      "FP: 1866 0.0369336737723 \n",
      "TN: 48657 0.963066326228 \n",
      "FN: 182 0.0294689119171\n",
      "\n",
      "BDB =  0.2 \n",
      "TP: 5895 0.954501295337 \n",
      "FP: 1227 0.0242859687667 \n",
      "TN: 49296 0.975714031233 \n",
      "FN: 281 0.0454987046632\n",
      "\n",
      "BDB =  0.3 \n",
      "TP: 5796 0.938471502591 \n",
      "FP: 883 0.0174771886072 \n",
      "TN: 49640 0.982522811393 \n",
      "FN: 380 0.0615284974093\n",
      "\n",
      "BDB =  0.4 \n",
      "TP: 5683 0.920174870466 \n",
      "FP: 659 0.0130435643172 \n",
      "TN: 49864 0.986956435683 \n",
      "FN: 493 0.0798251295337\n",
      "\n",
      "BDB =  0.5 \n",
      "TP: 5540 0.897020725389 \n",
      "FP: 503 0.00995586168676 \n",
      "TN: 50020 0.990044138313 \n",
      "FN: 636 0.102979274611\n",
      "\n",
      "BDB =  0.6 \n",
      "TP: 5393 0.873218911917 \n",
      "FP: 381 0.00754111988599 \n",
      "TN: 50142 0.992458880114 \n",
      "FN: 783 0.126781088083\n",
      "\n",
      "BDB =  0.7 \n",
      "TP: 5185 0.83954015544 \n",
      "FP: 271 0.00536389367219 \n",
      "TN: 50252 0.994636106328 \n",
      "FN: 991 0.16045984456\n",
      "\n",
      "BDB =  0.8 \n",
      "TP: 4902 0.79371761658 \n",
      "FP: 166 0.00328563228629 \n",
      "TN: 50357 0.996714367714 \n",
      "FN: 1274 0.20628238342\n",
      "\n",
      "BDB =  0.9 \n",
      "TP: 4490 0.727007772021 \n",
      "FP: 101 0.00199908952358 \n",
      "TN: 50422 0.998000910476 \n",
      "FN: 1686 0.272992227979\n",
      "\n",
      "\n",
      "Gradient Boosting Regressor:\n",
      "R^2 Score: 0.848231559571\n",
      "\n",
      "BDB =  0.0 \n",
      "TP: 6157 0.99692357513 \n",
      "FP: 26752 0.529501415197 \n",
      "TN: 23771 0.470498584803 \n",
      "FN: 19 0.00307642487047\n",
      "\n",
      "BDB =  0.1 \n",
      "TP: 6012 0.973445595855 \n",
      "FP: 1951 0.0386160758466 \n",
      "TN: 48572 0.961383924153 \n",
      "FN: 164 0.0265544041451\n",
      "\n",
      "BDB =  0.2 \n",
      "TP: 5894 0.954339378238 \n",
      "FP: 1210 0.0239494883518 \n",
      "TN: 49313 0.976050511648 \n",
      "FN: 282 0.0456606217617\n",
      "\n",
      "BDB =  0.3 \n",
      "TP: 5794 0.938147668394 \n",
      "FP: 864 0.0171011222611 \n",
      "TN: 49659 0.982898877739 \n",
      "FN: 382 0.0618523316062\n",
      "\n",
      "BDB =  0.4 \n",
      "TP: 5679 0.919527202073 \n",
      "FP: 629 0.0124497753498 \n",
      "TN: 49894 0.98755022465 \n",
      "FN: 497 0.0804727979275\n",
      "\n",
      "BDB =  0.5 \n",
      "TP: 5551 0.898801813472 \n",
      "FP: 487 0.00963917423748 \n",
      "TN: 50036 0.990360825763 \n",
      "FN: 625 0.101198186528\n",
      "\n",
      "BDB =  0.6 \n",
      "TP: 5412 0.876295336788 \n",
      "FP: 356 0.00704629574649 \n",
      "TN: 50167 0.992953704254 \n",
      "FN: 764 0.123704663212\n",
      "\n",
      "BDB =  0.7 \n",
      "TP: 5201 0.842130829016 \n",
      "FP: 253 0.00500762029175 \n",
      "TN: 50270 0.994992379708 \n",
      "FN: 975 0.157869170984\n",
      "\n",
      "BDB =  0.8 \n",
      "TP: 4882 0.790479274611 \n",
      "FP: 144 0.00285018704352 \n",
      "TN: 50379 0.997149812956 \n",
      "FN: 1294 0.209520725389\n",
      "\n",
      "BDB =  0.9 \n",
      "TP: 4279 0.692843264249 \n",
      "FP: 73 0.00144488648734 \n",
      "TN: 50450 0.998555113513 \n",
      "FN: 1897 0.307156735751\n",
      "\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "R^2 Score: 0.980017284255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell tells the accuracy of the model.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model = etr\n",
    "print 'Extra Trees Regressor:'\n",
    "print 'R^2 Score:', model.score(testX, testY)\n",
    "print\n",
    "for i in np.arange(0.0, 1.0, 0.1):\n",
    "    printEval(model, testX, testY, i)\n",
    "    print\n",
    "print\n",
    "\n",
    "model = rfr\n",
    "print 'Random Forest Regressor:'\n",
    "print 'R^2 Score:', model.score(testX, testY)\n",
    "print\n",
    "for i in np.arange(0.0, 1.0, 0.1):\n",
    "    printEval(model, testX, testY, i)\n",
    "    print\n",
    "print\n",
    "\n",
    "model = gbr\n",
    "print 'Gradient Boosting Regressor:'\n",
    "print 'R^2 Score:', model.score(testX, testY)\n",
    "print\n",
    "for i in np.arange(0.0, 1.0, 0.1):\n",
    "    printEval(model, testX, testY, i)\n",
    "    print\n",
    "print\n",
    "\n",
    "model = gbc\n",
    "print 'Gradient Boosting Classifier:'\n",
    "print 'R^2 Score:', model.score(testX, testY)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def printEval(model, X, y, bdb = 0.5):\n",
    "    predY = model.predict(X)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if predY[i] > bdb and y[i] == 1:\n",
    "            tp += 1\n",
    "        elif predY[i] > bdb and y[i] == 0:\n",
    "            fp += 1\n",
    "        elif predY[i] <= bdb and y[i] == 1:\n",
    "            fn += 1\n",
    "        elif predY[i] <= bdb and y[i] == 0:\n",
    "            tn += 1\n",
    "            \n",
    "    print 'BDB = ', bdb, '\\nTP:', tp, tp/(tp+fn), '\\nFP:', fp, fp/(fp+tn), '\\nTN:', tn, tn/(fp+tn), '\\nFN:', fn, fn/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save the model.\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "#pickle.dump(etr, open('/users/cs/amaral/wikisim/wikification/ml-models/model-etr-1.pkl', 'wb'))\n",
    "#pickle.dump(rfr, open('/users/cs/amaral/wikisim/wikification/ml-models/model-rfr-1.pkl', 'wb'))\n",
    "#pickle.dump(gbr, open('/users/cs/amaral/wikisim/wikification/ml-models/model-gbr-1.pkl', 'wb'))\n",
    "#pickle.dump(gbc, open('/users/cs/amaral/wikisim/wikification/ml-models/model-gbc-1.pkl', 'wb'))\n",
    "#pickle.dump(lmart, open('/users/cs/amaral/wikisim/wikification/ml-models/model-lmart-1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.38906408, -0.38142295,  0.14399559, -1.21259834,  6.16869182,\n",
       "        1.39566366,  6.07528854,  5.27429442, -5.77873421, -3.68008578,\n",
       "       -7.37840903, -6.02215263, -4.83235341, -5.99034009, -4.64082089,\n",
       "       -6.54484845, -3.38575076, -5.05438867])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "sys.path.append('./pyltr/')\n",
    "import pyltr\n",
    "\n",
    "model = pickle.load(open('/users/cs/amaral/wikisim/wikification/ml-models/model-lmart-1.pkl', 'rb'))\n",
    "\n",
    "model.predict(testX[2:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16, 0.37197801830625504, 0.75, 0.0, 0.8058462601912664], [0.12, 0.12183860865881956, 0.0, 0.0, 0.003000814788764128], [0.08, 0.15388780453451467, 0.0, 0.0, 0.0197314194384961], [0.04, 0.12183860865881956, 0.0, 0.0, 0.00597341299761156], [0.6666666666666666, 0.5524107765948493, 0.75, 0.0, 0.6424277609623221], [0.2222222222222222, 0.43160739972500395, 0.0, 0.0, 0.04122347126384451], [0.9875, 0.9595134734099676, 0.9090909090909091, 0.25918609576466367, 0.9999999999999998], [0.9585703450891164, 0.1346076964691621, 0.9090909090909091, 0.265528050509531, 0.6452690222713563], [0.010586525091644546, 0.0, 0.0, 0.13257166946600463, 0.0008528990630150002], [0.006415118189862217, 0.07584652897571567, 0.0, 0.18615200157548295, 0.021349869684028633], [0.004361016306408798, 0.0, 0.0, 0.13820647183391077, 0.0], [0.0034445708507141954, 0.0, 0.0, 0.2197684333582972, 0.001374533158081892], [0.002844141069397042, 0.06692287344969088, 0.0, 0.1855829880405545, 0.0038656172984994353], [0.0027177347996460623, 0.0, 0.0, 0.12775189841427181, 0.0008678591415569592], [0.002085703450891164, 0.0741983070523882, 0.0, 0.1666364333953726, 0.014134646571460907], [0.0015800783718872456, 0.0, 0.0, 0.13560885982084758, 0.0010101363516014095], [0.0011692579951965618, 0.13443111220948226, 0.0, 0.1846330840700947, 0.07855439768226724], [0.0009796485905700922, 0.0992152278375584, 0.0, 0.20990917625900218, 0.03458034001283328]]\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print testX[2:20]\n",
    "print\n",
    "print testY[2:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile el-data-gen.py \n",
    "\n",
    "\"\"\"\n",
    "This file/cell is to generate training data for entity linking for a supervised model.\n",
    "Each row has form: (id, isTrueEntity, popularity, context1, context2, word2vec, coherence, mentionId)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from wikification import *\n",
    "import copy\n",
    "import sys\n",
    " \n",
    "def normalize(nums):\n",
    "    \"\"\"Normalizes a list of nums to its sum + 1\"\"\"\n",
    "    \n",
    "    numSum = sum(nums) + 1 # get max\n",
    "    \n",
    "    # fill with normalized\n",
    "    normNums = []\n",
    "    for num in nums:\n",
    "        normNums.append(num/numSum)\n",
    "        \n",
    "    return normNums\n",
    "\n",
    "pathStrt = '/users/cs/amaral/wsd-datasets'\n",
    "dsPath = os.path.join(pathStrt,'wiki-mentions.5000.json')\n",
    "\n",
    "with open(dsPath, 'r') as dataFile:\n",
    "    dataLines = []\n",
    "    i = 0\n",
    "    for line in dataFile:\n",
    "        dataLines.append(json.loads(line.decode('utf-8').strip()))\n",
    "        i += 1\n",
    "        if i > 5000:\n",
    "            break\n",
    "        \n",
    "cPerM = 20 # candidates per mention\n",
    "\n",
    "allCands = []\n",
    "\n",
    "# word2vec loading\n",
    "try:\n",
    "    word2vec\n",
    "except:\n",
    "    print 'loading word2vec'\n",
    "    word2vec = gensim_loadmodel('/users/cs/amaral/cgmdir/WikipediaClean5Negative300Skip10.Ehsan/WikipediaClean5Negative300Skip10')\n",
    "\n",
    "print 'word2vec loaded'\n",
    "    \n",
    "f = 0\n",
    "\n",
    "mNum = 0\n",
    "# see each line\n",
    "for line in dataLines:\n",
    "    \n",
    "    oMentions = copy.deepcopy(line['mentions']) # mentions in original form\n",
    "    oText = \" \".join(copy.deepcopy(line['text']))\n",
    "    \n",
    "    line['mentions'] = mentionStartsAndEnds(line)\n",
    "    # get what should be all candidates\n",
    "    candidates = generateCandidates(line, 999, True)\n",
    "    \n",
    "    i = 0\n",
    "    for i in range(0, len(candidates)):\n",
    "        entId = title2id(oMentions[i][1])\n",
    "        j = 0\n",
    "        candsRepl = []\n",
    "        for cand in candidates[i]:\n",
    "            if j >= cPerM:\n",
    "                break\n",
    "            \n",
    "            if cand[0] == entId:\n",
    "                candsRepl.append([entId, 1, cand[1]]) # put in correct cand id and popularity\n",
    "                j += 1\n",
    "            elif j < cPerM:\n",
    "                candsRepl.append([cand[0], 0, cand[1]]) # put false cand in\n",
    "                j += 1\n",
    "        candidates[i] = candsRepl\n",
    "    \n",
    "    i = 0 # index of mention\n",
    "    \n",
    "    hasCoherence = False # whether coherence scores for this line were obtained\n",
    "    \n",
    "    # see each mention\n",
    "    for mention in oMentions:\n",
    "    \n",
    "        entId = title2id(mention[1]) # id of the true entity\n",
    "                \n",
    "        candList = candidates[i]\n",
    "        \n",
    "        # normalize popularity scores\n",
    "        cScrs = []\n",
    "        for cand in candList:\n",
    "            cScrs.append(cand[2])\n",
    "        cScrs = normalize(cScrs)\n",
    "        j = 0\n",
    "        for cand in candList:\n",
    "            cand[2] = cScrs[j]\n",
    "            j += 1\n",
    "          \n",
    "        # get score from context1 method\n",
    "        context = getMentionsInSentence(line, line['mentions'][i]) # get context for some w methods\n",
    "        cScrs = getContext1Scores(line['text'][mention[0]], context, candList)\n",
    "        cScrs = normalize(cScrs)\n",
    "        # apply score to candList\n",
    "        for j in range(0, len(candList)):\n",
    "            candList[j].append(cScrs[j])\n",
    "            \n",
    "        # get score from context2 method\n",
    "        context = getMentionsInSentence(line, line['mentions'][i]) # get context for some w methods\n",
    "        cScrs = getContext2Scores(line['text'][mention[0]], context, candList)\n",
    "        cScrs = normalize(cScrs)\n",
    "        # apply score to candList\n",
    "        for j in range(0, len(candList)):\n",
    "            candList[j].append(cScrs[j])\n",
    "        \n",
    "        # get score form word2vec\n",
    "        context = getMentionSentence(oText, line['mentions'][i], asList = True)\n",
    "        cScrs = getWord2VecScores(context, candList)\n",
    "        #cScrs = normalize(cScrs)\n",
    "        # apply score to candList\n",
    "        for j in range(0, len(candList)):\n",
    "            candList[j].append(cScrs[j])\n",
    "\n",
    "        # get score from coherence\n",
    "        if hasCoherence == False:\n",
    "            cohScores = coherence_scores_driver(candidates, 5, method='rvspagerank', direction=DIR_BOTH, op_method=\"keydisamb\")\n",
    "            hasCoherence = True\n",
    "        for j in range(0, len(candList)):\n",
    "            candList[j].append(cohScores[i][j])\n",
    "            \n",
    "        # put the mention id\n",
    "        for j in range(len(candList)):\n",
    "            candList[j].append(mNum)\n",
    "            \n",
    "        allCands.append(candList)\n",
    "        \n",
    "        mNum += 1\n",
    "        \n",
    "        i += 1\n",
    "    f += 1\n",
    "    print 'Line: ' + str(f)\n",
    "        \n",
    "\n",
    "with open('/users/cs/amaral/wikisim/wikification/learning-data/el-5000-hybridgen.txt', 'w') as f:\n",
    "    for thing in allCands:\n",
    "        for thingy in thing:\n",
    "            f.write(str(thingy)[1:-1] + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# April  16\n",
    "1. created a surface-replace by skipping the opening, it's being trained with windows sized 5 and 10\n",
    "a normal surface-replae is being trained with window 5, so now I have windows size 5 and 10 for both, with dimensionaltiy 500\n",
    "\n",
    "2. I modifid the context to contain source id and title, and paragraph no. It's been created, I deleted the index, and restarted, so ready to import\n",
    "\n",
    "## TODO\n",
    "1. run the split:\n",
    "go to    \n",
    "`cat ~/backup/datasets/cmod/contexts.json | split -a 10 -l 500000 - context`   \n",
    "2. bash loadwiki: done\n",
    "3. bash optimize: done\n",
    "4. ** HOW TO modify materialization? **\n",
    "5. Create the mentions for the guy (openning text?)\n",
    "4. Evaluate the graph embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# April 18\n",
    "1. word2vec Embedding are trained, with skip line and everything\n",
    "# TODO\n",
    "materialization kinda done, but not very much tested. you see a file (old.delet), that should be th ground truth\n",
    "so, go ahead and do the following\n",
    "0. There is an issue with the naming the train and test\n",
    "1. try with no skip line and downsample, check the results be the sample as the old one\n",
    "2. if yes, try with skip line, take a look, compare the logs (which tells you how many in train and test)\n",
    "3. if correct, run one with max_anchor 1000, and one with no down sample\n",
    "4. integize all\n",
    "5. zip the cmod dir and save it in a good place\n",
    "6. create the mentions for the guy\n",
    "7. sync with ares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a     test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "April 21\n",
    "almost all done\n",
    "The materialization is being done, just integize it and you're good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "# Wikisim\n",
    "## Wikisim provides the following services:\n",
    "* **Vector-Space Representation of Wikipedia Concepts**\n",
    "* **Semantic Relatedness between Wikipedia Concepts**\n",
    "* **Wikification: Entity Linking to Wikipedia**\n",
    "\n",
    "* For a more detailed document and the main algorithm, check:\n",
    "\n",
    "* [Wikisim Notebook](wikisim/wikisim.ipynb)\n",
    "This is a simple and step by step explanation of concept-representation and calculating semantic relatedness using Wikipedia. We start by preprocessing and building the api.\n",
    "\n",
    "* [Wikification Notebook](wikification/wikify.ipynb)\n",
    "This notbook contains Word-sense Disambiguation/Wikifaction modules\n",
    "\n",
    "* **Armin Sajadi** - Faculty of Computer Science\n",
    "* **Dr. Evangelos Milios** - Faculty of Computer Science\n",
    "* **Dr. Vlado Kešelj** – Faculty of Computer Science\n",
    "\n",
    "\n",
    "Single mode\n",
    "The webservice provides two basic functions (or tasks): Embedding and Simiarity calculation. Both requests can be processed in single or batch mode.\n",
    "\n",
    "* Concept Representation (Embedding):\n",
    "parameters: \n",
    "\n",
    "`task` : should be 'emb' for this task \n",
    "\n",
    "`direction`: 0 for using incomming links, 1 for outgoing links and 2 for both. We recommend using only outgoing links as it provides decent results and is significantly faster \n",
    "\n",
    "`cutoff`: the dimensionality of the embedding. This parameter is only used for returning the embeddings, the similarity calculation always uses all the dimensions. \n",
    "\n",
    "`c1` : the concept to be processed \n",
    "\n",
    "Example (using curl): \n",
    "`curl --request POST 'http://ares.research.cs.dal.ca/~sajadi/wikisim/cgi-bin/cgi-pairsim.py' --data \"task=emb\" --data \"dir=1\" --data \"cutoff=10\" --data \"c1=Sanandaj\"`\n",
    "\n",
    "* Similarity parameters: \n",
    "`task`: should be 'sim' for this task \n",
    "`direction`: 0 for using incomming links, 1 for outgoing links and 2 for both. We recommend using only outgoing links as it provides decent results and is significantly faster\n",
    "\n",
    "`c1` (and `c2`): the concept to be processed\n",
    "\n",
    "Example (using curl): \n",
    "curl --request POST 'http://ares.research.cs.dal.ca/~sajadi/wikisim/cgi-bin/cgi-pairsim.py' --data \"task='sim'\" --data \"dir=1\" --data \"c1=Tehran\" --data \"c2=Sanandaj\"\n",
    "Batch mode\n",
    "We strongly recommend using batch mode, either by post request and sending the file, or simply uploading the file in the batch mode input. For embeddings, each line of the file contains a single concept. For similarity calculation, file should be tab seperated, each line containing a pair of Wikipedia Concepts.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Armin Sajadi, Evangelos E. Milios, Vlado Keselj, \"Vector Space Representation of Concepts Using Wikipedia Graph Structure\", Submitted to NLDB 2017\n",
    "\n",
    "### Public Resources\n",
    "* Weservice: (http://web.cs.dal.ca/~sajadi/wikisim/)\n",
    "* Source Code: (https://github.com/asajadi/wikisim)\n",
    "\n",
    "\n",
    "# Installation\n",
    "## install [conda] (https://www.anaconda.com/download)\n",
    "## conda env create -f environment.yml\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel-body\">\n",
    "    <h2> Single mode </h2>\n",
    "    <p>The webservice provides three basic functions (or tasks): \n",
    "        Wikification, Simiarity and Embedding calculation. All requests can be processed in\n",
    "        <em>single</em> or <em>batch mode</em>.\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <strong>Wikification:</strong> <br>\n",
    "            parameters: <br>\n",
    "            <code>mentionmethod</code>: should be 0 for using <em>CoreNLP</em>, 1 \n",
    "            for our <em>high-precision trained model</em> and 2 for our <em>high-recall trained method</em><br>\n",
    "            <code>text</code>: the text to be wikified\n",
    "        </li>\n",
    "        <li>\n",
    "            <strong>Similarity Calculation</strong>: <br>\n",
    "            parameters: <br>\n",
    "            <code>task</code>: should be 'sim' for this task <br>\n",
    "            <code>direction</code>: 0 for using incomming links, 1 for outgoing links and 2 for both. We recommend using only\n",
    "            outgoing links as it provides decent results and is significantly faster<br>\n",
    "            <code>c1 (and c2)</code>: the concept to be processed<br>\n",
    "            Example (using curl): <br>\n",
    "            <code>curl --request POST 'http://ares.research.cs.dal.ca/~sajadi/wikisim/cgi-bin/cgi-pairsim.py' --data \"task='sim'\" --data \"dir=1\"  --data \"c1=Tehran\" --data \"c2=Sanandaj\"</code>\n",
    "        </li>        \n",
    "        <li>\n",
    "            <strong>Concept Representation (Embedding): </strong><br>\n",
    "            parameters: <br>\n",
    "            <code>task</code>: should be 'emb' for this task <br>\n",
    "            <code>direction</code>: 0 for using\n",
    "            <em>incomming links</em>, 1 for\n",
    "            <em>outgoing links</em> and 2 for\n",
    "            <em>both</em>. We recommend using only outgoing links as it provides decent results and is significantly\n",
    "            faster\n",
    "            <br>\n",
    "            <code>cutoff</code>: the dimensionality of the embedding. This parameter is only used for returning the embeddings,\n",
    "            the similarity calculation always uses all the dimensions. <br>\n",
    "            <code>c1</code>: the concept to be processed <br>\n",
    "            Example (using curl): <br>\n",
    "            <code>curl --request POST 'http://ares.research.cs.dal.ca/~sajadi/wikisim/cgi-bin/cgi-pairsim.py' --data \"task=emb\" --data \"dir=1\" --data \"cutoff=10\" --data \"c1=Sanandaj\"</code>\n",
    "        </li>\n",
    "    </ul>\n",
    "    <h2> Batch mode </h2>\n",
    "    <p>We strongly recommend using batch mode, either by post request and sending the file, or simply uploading\n",
    "        the file in the batch mode input. For embeddings, each line of the file contains a single concept.\n",
    "        For similarity calculation, file should be tab seperated, each line containing a pair of Wikipedia\n",
    "        Concepts. </p>\n",
    "    <p>The parameters are the same, however, the target cgi-files are different:</p>\n",
    "    <ul>\n",
    "        <li>\n",
    "            Wikification: use <code>cgi-batchwikify.py</code><br>\n",
    "            Example (using curl): <br>\n",
    "            <code></code>            \n",
    "        </li>\n",
    "        <li>\n",
    "            Wikification: use <code>cgi-batchsim.py</code><br>\n",
    "            Example (using curl): <br>\n",
    "            <code></code>            \n",
    "        </li>\n",
    "        <li>\n",
    "            Wikification: use <code>cgi-batchsim.py</code><br>\n",
    "            Example (using curl): <br>\n",
    "            <code></code>            \n",
    "        </li>\n",
    "    </ul>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>\n",
    "        Concept Representation (Embedding):<br>\n",
    "        parameters: <br>\n",
    "        <code>task</code>: should be 'emb' for this task <br>\n",
    "        <code>direction</code>: 0 for using\n",
    "        <em>incomming links</em>, 1 for\n",
    "        <em>outgoing links</em> and 2 for\n",
    "        <em>both</em>. We recommend using only outgoing links as it provides decent results and is significantly\n",
    "        faster\n",
    "        <br>\n",
    "    </li>\n",
    "   </ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Concept Representation (Embedding):<br>\n",
    "            parameters: <br> test\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
